bnai  belg nl ai conf.


herkenning van maatsoort/patronen
  speech to song illusion - na repetitie

verschillen personen/culturen - herkennig ..


muzikanten - logic etc


timidity - midi to audio python
tsni - pca, analysis many-D to 2D


e.g. 4/4 3/4

compresson distance papaer


model
 - good trainig performance, but bad validation
   - likely caused by lack of trainging/data/model-size
   - no problem for style transfer?
     - risk: all generated samples may be in the training dataset

evaluation
- experimental:
  - ask musicians whether they recognize generated samples as bellonging to genre x
  - ask if there are distinct properties that are shown or lacking
- analytical
  - compression: f(a) + f(b) vs f(a+b)
    - with bz2, zip
    - Point-Set Compression Algorithms
        - COSIATEC, SIATECCompress etc.
    - alt. representations, midi, GUIDO music notation
     - rdf

    hypothesis, for samples a, b from genres a,b
     f(a1) + f(a2) == 2 * f(a1+a2)
     f(a) + f(b) == f(a+b)




relevance for music-research
- which features are present in genre x and not in other genres
- model biased on training data, but not in the same way humans are biased
  - can these kind of models circumvent this bias and open doors to new insights?


betere data: train with many genres, then do experiment with 3 genres





ai c - november - conferentie

significance
 - theory - leren van resultaten, muziek/stijl-kenmerken beter begrijpen
 - theory - nieuwe patronen/technieken leren
    - net als leren van schaak/go computer
 - creativity - helpen
   - variaties van zelf ingespeelde muziek



midi zoeken (genres kiezen)
 - midi cloud - albert?


code
 - phase augmentation?
 - n bars, resolution 
   - fills















google cloud
JMVAE
batch size lager
spotif

todo check tempo information per song (min, max of dataset)
y api - validation?
 - classificatie op genre

As midi is a compressed format of musical data, it lack a significant amount of information compared to audio files []. Especially for drums, the differences between modern pop songs are not most prominent in the patterns itself, but rather in the dynamics and voicings of the musician, which results in differences in timbre (frequency, spectrum). There are much more differences in the rythms itself between different genres (e.g. pop, jazz, metal, world). Therefore this is chosen.
- drum-midi collection: 800.000 midifiles (loops + songs), different sources + styles

MusicVAE
 - quantized (16th notes), this causes the output to always be in time
  - no triplets
  - no swing/shuffle/laid-back
 for e.g. the closed hihat, the model can always predict a value of 1.0 and the output can still be musical
 alt: higher samplerate, less quantization, more sparse matrices


latent space
 - normaal veel samples nodig (variatie)
  - maar met hierarchical model hoeft dat niet


evaluatie ~ analytisch
 - spotify
 - cons jos


softmax ouptut for poly data?

sparse matrices?
 - musicVAE was quantized to 16ths

normalize




Hypothesis testing
 - experimental
 - analytical (+ part experimental)


How much quantization can be used while maintaining musical qualities 
What effect has quantization on ..
e.g. dilla analysis


data
 - limit variance: e.g. 2 'pure' genres (e.g. typical rock beat)
   - instead of class probabilities, latent variabels become scalars for musical features that are present in one or more genres (e.g. hh density)
 - then interpolations becomes more meaningfull


Subjects ~ style transfer
 - melodies
 - sparse matrices ~ swing, shuffle
 - rdf, semantic ...
 - psychology/perception: conv. based network vs capsule based
  - independent identification and property detection
  - vector graphics
 - practical application?


Beoordelen
 cross-entropy, accuracy
 hits/misses, sensitivity
 experimental study
 manually:
  for x in true hits: dt with pred x




---

tools

pretrained models - google magenta

