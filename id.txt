So far
	convert midi to matrices
	autoencoder, normal + lstm
		high accuracy caused by 95% of the data being 0
	output is still different than inut


todo
	sparse matrices (scipy/tensorflow)
		or generators


id:
  simulate recorders with multiple sample rates,
  by using LSTM networks with different input windows
  - just like with recording
  - so that multiple patterns with different frequences can be analysed
  	e.g. HH of 2 Hz, BD of 0.25 Hz
  	e.g. 3 over 2



Database

database van drumloops - genoeg keuze, maar geen structuur in labels etc (veel overlappende labels)

noten corresponderen niet met instrumenten
 - no inherent difference between HH, OH




change encoder:
       [ [ occurences per instance ] per note ]
       then use conv layers to decrease the amount of nodes
       (notes are considered to be independent instruments)
       combine the nodes post, with some sparse layers (conv removes too much info)


large amount (10k) of inputs
 - hierarchical softmax, negative sampling







doel project
 - onderzoek midi in ml
 	- toetsen van generatieve modellen?

---

Haalbaarheid

verschillende onderwerpen
- (poly) ritme herkenning 		
	- maatherkenning
	- deconstructie van partijen 		e.g. 3 over 2

- generatieve modellen
	- variatie
	- variatie naar stijlen/genres  	(variatie over 1 component)
		- analyse van kwaliteit van componenten (overeenkomst met stijl)

- herkennen van stijl

- web-applicatie
	- input midi file (loop)
	- analyseer tempo/ritme
	- genereer variaties


polyphony?



---

tools

pretrained models - google magenta

