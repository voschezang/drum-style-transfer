{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas, sklearn\n",
    "import mido, rtmidi, rtmidi_\n",
    "np.random.seed(333)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## NN libs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Input, Dense, Activation, Conv1D, Conv2D, Dropout, Flatten\n",
    "from keras.layers import Conv2DTranspose, Reshape, MaxPooling2D, UpSampling2D, UpSampling1D, MaxPooling1D\n",
    "from keras.layers import LocallyConnected1D, LocallyConnected2D\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# local libs\n",
    "import config\n",
    "from data import data, midi\n",
    "from utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      " >> Context(max_t=3.0, dt=0.1, n_instances=30, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Importing midi-data\n",
      "\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/01 16th Snare.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/01 8th Cym.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/01 8th Hat.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/02 8th Cym.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/114_LetsDance_DavidBowie1.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/127_SweetChildOMine_GunsAndRoses1.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/92_GiveItAway_TheRedHotChiliPeppers.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/94_Creep_Radiohead2.mid\n",
      "\n",
      "Encoding midi-data\n",
      " [<midi file '../datasets/examples/01 16th Snare.mid' type 0, 1 tracks, 182 messages>, <midi file '../datasets/examples/01 8th Cym.mid' type 0, 1 tracks, 68 messages>, <midi file '../datasets/examples/01 8th Hat.mid' type 0, 1 tracks, 60 messages>, <midi file '../datasets/examples/02 8th Cym.mid' type 0, 1 tracks, 72 messages>, <midi file '../datasets/examples/114_LetsDance_DavidBowie1.mid' type 0, 1 tracks, 76 messages>, <midi file '../datasets/examples/127_SweetChildOMine_GunsAndRoses1.mid' type 0, 1 tracks, 226 messages>, <midi file '../datasets/examples/92_GiveItAway_TheRedHotChiliPeppers.mid' type 0, 1 tracks, 132 messages>, <midi file '../datasets/examples/94_Creep_Radiohead2.mid' type 0, 1 tracks, 126 messages>]\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9531250000000004\n",
      " |>  30\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.989583333333333\n",
      " |>  30\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9947916666666665\n",
      " |>  30\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9895833333333335\n",
      " |>  30\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.999999999999999\n",
      " |>  30\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0\n",
      " |>  30\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.958333333333333\n",
      " |>  30\n",
      "[DEBUG] >\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0000000000000004\n",
      " |>  30\n",
      "(8, 30, 4)\n"
     ]
    }
   ],
   "source": [
    "n: int = 8\n",
    "context, x_train, labels = data.import_data(data.init(),n)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "Input -> hidden layer -> output (=input)\n",
    "Hidden layer has few dimension. Latent space of this layer should produce automatic categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 30, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = x_train\n",
    "n_samples = x_train[0]\n",
    "input_shape = x_train.shape[1:] # shape of a single sample\n",
    "output_shape = y_train.shape[1:]\n",
    "# output_length = y_train.shape[1]\n",
    "# output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "hidden_layer_length = 100\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 30, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 30, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = x_train\n",
    "n_samples = x_train[0]\n",
    "input_shape = x_train.shape[1:] # shape of a single sample\n",
    "output_shape = y_train.shape[1:]\n",
    "# output_length = y_train.shape[1]\n",
    "# output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "hidden_layer_length = 100\n",
    "timesteps = input_shape[0]\n",
    "input_length = input_shape[1]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims = (None, 100) 100\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 30, 4)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30, 127)           635       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               91200     \n",
      "=================================================================\n",
      "Total params: 91,835\n",
      "Trainable params: 91,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 30, 4)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30, 127)           635       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               91200     \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 4)             1680      \n",
      "=================================================================\n",
      "Total params: 93,515\n",
      "Trainable params: 93,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(timesteps, input_length))\n",
    "x = inputs\n",
    "x = Dense(127, activation='relu')(x)\n",
    "encoded = LSTM(hidden_layer_length)(x)\n",
    "dims = keras.backend.int_shape(encoded)\n",
    "print('dims =', dims, hidden_layer_length)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_length, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "encoder.summary()\n",
    "sequence_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy','mse','categorical_crossentropy']\n",
    "loss = 'binary_crossentropy' # binary_crossentropy categorical_crossentropy\n",
    "optimizer = 'adadelta'\n",
    "# learning_rate = 0.001\n",
    "# optimizer = optimizer = Adam(lr=learning_rate)\n",
    "sequence_autoencoder.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "encoder.compile(optimizer='adadelta', loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples, validate on 2 samples\n",
      "Epoch 1/15\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 1.1523 - acc: 0.8903 - mean_squared_error: 0.1107 - categorical_crossentropy: 3.4701 - val_loss: 0.2820 - val_acc: 0.8750 - val_mean_squared_error: 0.1007 - val_categorical_crossentropy: 8.0590\n",
      "Epoch 2/15\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2490 - acc: 0.8903 - mean_squared_error: 0.0879 - categorical_crossentropy: 6.7159 - val_loss: 0.2512 - val_acc: 0.8750 - val_mean_squared_error: 0.0951 - val_categorical_crossentropy: 6.4472\n",
      "Epoch 3/15\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2247 - acc: 0.8903 - mean_squared_error: 0.0837 - categorical_crossentropy: 4.5668 - val_loss: 0.2312 - val_acc: 0.8750 - val_mean_squared_error: 0.0908 - val_categorical_crossentropy: 1.8804\n",
      "Epoch 4/15\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2097 - acc: 0.8903 - mean_squared_error: 0.0808 - categorical_crossentropy: 2.3282 - val_loss: 0.2176 - val_acc: 0.8750 - val_mean_squared_error: 0.0880 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 5/15\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1987 - acc: 0.8903 - mean_squared_error: 0.0787 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.2067 - val_acc: 0.8750 - val_mean_squared_error: 0.0858 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 6/15\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1912 - acc: 0.8903 - mean_squared_error: 0.0772 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1992 - val_acc: 0.8750 - val_mean_squared_error: 0.0845 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 7/15\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1858 - acc: 0.8903 - mean_squared_error: 0.0770 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1939 - val_acc: 0.8750 - val_mean_squared_error: 0.0838 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 8/15\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1822 - acc: 0.8903 - mean_squared_error: 0.0765 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1899 - val_acc: 0.8750 - val_mean_squared_error: 0.0835 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 9/15\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1798 - acc: 0.8903 - mean_squared_error: 0.0771 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1873 - val_acc: 0.8750 - val_mean_squared_error: 0.0834 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 10/15\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1782 - acc: 0.8903 - mean_squared_error: 0.0768 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1852 - val_acc: 0.8750 - val_mean_squared_error: 0.0833 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 11/15\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1771 - acc: 0.8972 - mean_squared_error: 0.0773 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1839 - val_acc: 0.8750 - val_mean_squared_error: 0.0832 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 12/15\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1766 - acc: 0.9028 - mean_squared_error: 0.0772 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1830 - val_acc: 0.8750 - val_mean_squared_error: 0.0831 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 13/15\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1760 - acc: 0.9042 - mean_squared_error: 0.0774 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1824 - val_acc: 0.8750 - val_mean_squared_error: 0.0829 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 14/15\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1758 - acc: 0.9056 - mean_squared_error: 0.0773 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1820 - val_acc: 0.8750 - val_mean_squared_error: 0.0827 - val_categorical_crossentropy: 5.9605e-08\n",
      "Epoch 15/15\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1758 - acc: 0.9056 - mean_squared_error: 0.0770 - categorical_crossentropy: 5.2320e-08 - val_loss: 0.1816 - val_acc: 0.8750 - val_mean_squared_error: 0.0824 - val_categorical_crossentropy: 5.9605e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120b23940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_autoencoder.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_log_dir)])\n",
    "# model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n",
    "# model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "#           validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = encode.predict(x_train)\n",
    "n = result.shape[0]\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale/normalize data, based on features\n",
    "# axis determines whether the data is scaled based on the 'global' features\n",
    "# axis = 0: max per feature (between instances)\n",
    "# axis = 1: max per instance (ignore features)\n",
    "# e.g. np.arange(9).reshape(3,3).max(axis=0)\n",
    "\n",
    "a = preprocessing.minmax_scale(np.arange(9).reshape(3,3), axis=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = preprocessing.normalize(result, axis=0)\n",
    "# normalized = preprocessing.minmax_scale(result, axis=0)\n",
    "# normalized = preprocessing.robust_scale(result, axis=0, quantile_range=(25, 75))\n",
    "normalized[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:,2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized[0,:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalized\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(latent[:,0], latent[:,1], c=y_test[:num], alpha=0.1)\n",
    "# plt.scatter(result[:,0],result[:,1])\n",
    "plt.scatter(data[:3, 0], data[:3, 1], data='o', c=[0.4]*3)\n",
    "plt.scatter(data[4:, 0], data[4:, 1], data='^', c=[0.5]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 0\n",
    "y_dim = 1\n",
    "c_dim = 2\n",
    "plt.subplots_adjust(bottom = 0.1)\n",
    "plt.scatter(\n",
    "    data[:, x_dim], data[:, y_dim], marker='o', c=data[:, c_dim], alpha=0.9, s=[50 for _ in range(n)],\n",
    "    cmap=plt.get_cmap('Spectral'))\n",
    "\n",
    "for label, x, y in zip(labels, data[:, x_dim], data[:, y_dim]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-20, 20),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originals = result[0:2,]\n",
    "new = originals.mean(axis=0)\n",
    "arr = decode.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midis = [midi.decode_track(context, track) for track in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
