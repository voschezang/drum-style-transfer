{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "## NN libs\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os, numpy as np, pandas, sklearn, scipy.signal as signal\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local libs\n",
    "import config, models, setup\n",
    "import midi\n",
    "from midi import generators as g\n",
    "from utils import io, models_io, utils, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_timestesp = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n",
      "Setting up params\n",
      "\n",
      "max min f 10.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.05, n_timesteps=40, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      " sample length:  40.000000\n",
      " max_f: 10.000000, min_f: 0.500000\n"
     ]
    }
   ],
   "source": [
    "context = setup.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing midi-data\n",
      "\n",
      "Encoding midi-data\n",
      " 3\n",
      "> -> multi-track = True MidiFile\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  True\n"
     ]
    }
   ],
   "source": [
    "n = 3 * 1\n",
    "dim4 = True\n",
    "multiTrack = True\n",
    "reduce_dims = midi.ReduceDimsOptions.MIDIFILE # GLOBAL\n",
    "dn = 'drum_midi/'\n",
    "x_train, labels = setup.import_data(context, n, dim4=dim4, reduce_dims=reduce_dims, dirname=dn, multiTrack=multiTrack, r=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1000\n",
    "# min_f = 0\n",
    "# max_f = 3\n",
    "# x_train, params = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f,\n",
    "#     n_polyrythms=1,\n",
    "#     n_channels=3,\n",
    "#     d_phase=True,\n",
    "#     return_params=True,\n",
    "#     dim4=dim4,\n",
    "#     multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 40, 10, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 40, 10, 1), 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = int(x_train.shape[0] * 0.9)\n",
    "[x_train.shape, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_train[m:]\n",
    "x_train = x_train[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (40, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11729d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (40, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11734bd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0faa0848de6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "plot.single(x_train[0, :50,:,0])\n",
    "plot.single(x_train[1, :50,:,0])\n",
    "plot.single(x_train[2, :50,:,0])\n",
    "labels[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "timesteps = input_shape[0]\n",
    "notes = input_shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_shape, dropout=0.1):\n",
    "    encoder_input = Input(shape=input_shape)\n",
    "    nodes = np.prod(input_shape)\n",
    "\n",
    "    # Convolution\n",
    "    h = encoder_input\n",
    "    h = Reshape(input_shape[:-1])(h)\n",
    "    h = Conv1D(32, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "    h = Conv1D(64, kernel_size=2, strides=2, activation='relu', padding='valid')(h)\n",
    "    h = Conv1D(128, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "#     h = Dropout(dropout)(h) # uncomment when using larger batches\n",
    "\n",
    "    # RNN\n",
    "    shape = K.int_shape(h)[1:]\n",
    "    h = SimpleRNN(128)(h)\n",
    "\n",
    "    # Dense layers\n",
    "#     h = Flatten()(h)\n",
    "#     h = Dropout(dropout)(h) # uncomment when using larger batches\n",
    "    \n",
    "    h = Dense(intermediate_dim*2, activation='relu')(h)\n",
    "    h = Dense(intermediate_dim, activation='relu')(h)\n",
    "   \n",
    "    # Z Mean, Variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(h) # , activation='relu'\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(h) # , activation='relu'\n",
    "        \n",
    "    encoder_output = [z_mean, z_log_var]\n",
    "    encoder_model = Model(encoder_input, encoder_output, name='encoder_model-')\n",
    "    return encoder_model, encoder_input, z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model, encoder_input, z_mean, z_log_var = encoder(input_shape)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = lambda args: models.sample(args, z_mean, z_log_var, latent_dim, epsilon_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = Lambda(sampling)([z_mean, z_log_var])\n",
    "z_input = encoder_model(encoder_input)\n",
    "z_output = Lambda(sample_)(z_input)\n",
    "# z_output = Lambda(sampl_, output_shape=(latent_dim,))(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_decoders(output_shape, p='same'):\n",
    "    # decoder_input = z_output\n",
    "    # h = decoder_input\n",
    "    # :output_shape = (timesteps, channels, channels) || (batches, filters, timesteps, channels)\n",
    "    # keras offers just Conv2DTranspose and not Conv1DTranspose\n",
    "    # - use 2D images during upsampling :: (timesteps, notes, channels) => (timesteps, notes, filters)\n",
    "    # - use 1D images to optimize reconstruction :: (timesteps, filters) => (timesteps, notes)\n",
    "    \n",
    "    # image_data_format = 'channels_last'\n",
    "    # goal shape: (timesteps, notes, channels)\n",
    "    # start with the 'reverse': lots of small imgs => few large img\n",
    "    \n",
    "    timesteps, notes, channels = output_shape\n",
    "    time_ = int(timesteps/10)\n",
    "    notes_ = notes * 10\n",
    "    intermediate_dim = time_ * notes_ * channels\n",
    "    # at the start of upsampling, the image-structure does not yet have to correspond to the goal structure \n",
    "    # ?TODO use y*y*y starting dims, may conv, and only then correct the structure (?)\n",
    "    output_shape = (timesteps, notes, channels)\n",
    "    nodes = np.prod(output_shape)\n",
    "    \n",
    "    decoders = []\n",
    "    decoders += [ Dense(256, activation='relu') ]\n",
    "    decoders += [ Dense(256, activation='relu') ]\n",
    "    \n",
    "    # RNN\n",
    "    decoders += [ Reshape((8, 32)) ]\n",
    "    decoders += [ SimpleRNN(128, return_sequences='True') ]\n",
    "    # TODO 2nd RNN to generate the 'repeating' state (aka decay matrix)\n",
    "    decoders += [ Flatten() ]\n",
    "    decoders += [ Dense(nodes, activation='relu') ]\n",
    "    decoders += [ Dense(nodes, activation='relu') ]\n",
    "#     decoders += [ Dropout(0.05) ]\n",
    "\n",
    "#     # Convolution\n",
    "#     # Note that the kernel windows do not yet correspond to 'temporal' features, but rather to just spatial features\n",
    "#     k = (2,1) # (2,1) :: (timesteps, notes)\n",
    "#     s = (3,1)\n",
    "\n",
    "#     decoders += [ Reshape((time_, notes_, channels)) ]\n",
    "#     decoders += [ Conv2DTranspose(128, kernel_size=2, strides=3, activation='relu', padding=p) ]\n",
    "    \n",
    "#     # 'end' of upsampling\n",
    "#     decoders += [ Conv2D(32, kernel_size=(1,2), strides=(1,3), activation='relu', padding=p) ]\n",
    "\n",
    "    output_shape = (timesteps, notes, channels)\n",
    "    \n",
    "# #     decoders += [ Flatten()]\n",
    "#     decoders += [ Dense(np.prod(output_shape), activation='relu')]\n",
    "    decoders += [ Dense(np.prod(output_shape), activation='sigmoid')]\n",
    "    decoders += [ Reshape(output_shape)]\n",
    "    return decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoders = list_decoders(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = utils.composition(decoders, z_output, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "vae_input = encoder_input\n",
    "vae_output = decoded\n",
    "vae = Model(vae_input, vae_output)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute VAE loss\n",
    "def vae_loss(beta=1.):\n",
    "    # y_true, y_pred, z_mean, z_log_var, timesteps=150, notes=3, beta=1.\n",
    "    xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(vae_input), K.flatten(vae_output))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + beta * kl_loss)\n",
    "    return vae_loss\n",
    "\n",
    "vae_loss = vae_loss(beta=1)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "# vae.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "epochs = 1000\n",
    "params = {'batch_size': batch_size, 'return_y': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mod = 0.01\n",
    "whitening = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = 1\n",
    "useDataGenerator = False\n",
    "useDataGenerator = True\n",
    "\n",
    "x = x_train\n",
    "x = np.concatenate([x_train[:m] for _ in range(1000)])\n",
    "\n",
    "print('batch_size =', batch_size)\n",
    "if useDataGenerator:\n",
    "    datagen = models.ImageDataGenerator(x_train, batch_size, phase_mod, whitening)\n",
    "    history = collections.defaultdict(list)\n",
    "    n_batches = datagen.__len__()\n",
    "    for e in range(epochs):\n",
    "        print('\\n[Epoch %i/%i] >>>>>>>>>' % (e, epochs))\n",
    "        for batch_i, (x_batch, y_batch) in enumerate(datagen.flow(x[:m], x[:m], batch_size)):\n",
    "            print(' Batch %i/%i' % (batch_i,n_batches))\n",
    "            x_ = x_batch\n",
    "            x = datagen.shuffle_3rd_dim(x_batch)\n",
    "            h = vae.fit(x_, verbose=0)\n",
    "            for k,v in h.history.items(): \n",
    "                print(' \\\\_%s' % k, [round(v_,) for v_ in v])\n",
    "                history[k].append(v)\n",
    "            if batch_i >= n_batches:\n",
    "                break\n",
    "else:\n",
    "    h = vae.fit(x[:m], epochs=epochs, validation_data=(x_test, None))\n",
    "    history = h.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 30\n",
    "k = -1\n",
    "x = vae.predict(x_train[:100])\n",
    "plot.single(x_train[i, :50, :, 0])\n",
    "plot.single(x[i, :50, :, 0])\n",
    "plot.single(x_train[j, :50, :, 0])\n",
    "plot.single(x[j, :50, :, 0])\n",
    "plot.single(x_train[k, :50, :, 0])\n",
    "plot.single(x[k, :50, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min: these pixels are 'always' active\n",
    "m = x.min(axis=0)\n",
    "plot.multi(m[:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "m = x.mean(axis=0)\n",
    "plot.single(m[:30,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder + Generator\n",
    "A model to project inputs on the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(encoder_input, z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "x_train_encoded = encoder.predict(x_train[:m], batch_size=batch_size)\n",
    "x_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = range(x_train_encoded.shape[0])\n",
    "y_test = np.concatenate([list(range(n)) for _ in range(int(m/n)+1)])[:m] / n\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_train_encoded[:, 0], x_train_encoded[:, 1], alpha=0.8, s=30) # c=y_test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], alpha=0.6, s=30) # , c=y_test\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_decoded = utils.composition(decoders, decoder_input, verbose=False)\n",
    "generator = Model(decoder_input, _decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_decoded[0].reshape(150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = 0.01\n",
    "max_y = 0.5\n",
    "plot.latent(generator, batch_size,\n",
    "       n=8,\n",
    "       m=3,\n",
    "       crop_size=30,\n",
    "       margin_top=1,\n",
    "       margin_left=1,\n",
    "       min_x=0.05,\n",
    "       max_x=0.95,\n",
    "       min_y=min_y,\n",
    "       max_y=max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y2 = max_y\n",
    "plot.latent(generator, batch_size,\n",
    "       n=8,\n",
    "       m=3,\n",
    "       crop_size=30,\n",
    "       margin_top=1,\n",
    "       margin_left=1,\n",
    "       min_x=0.05,\n",
    "       max_x=0.95,\n",
    "       min_y=min_y2,\n",
    "       max_y=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
