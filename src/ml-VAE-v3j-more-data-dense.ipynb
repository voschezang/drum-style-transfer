{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "## NN libs\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os, numpy as np, pandas, sklearn, scipy.signal as signal\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local libs\n",
    "import config, models, setup\n",
    "import midi\n",
    "from midi import generators as g\n",
    "from utils import io, models_io, utils, plot\n",
    "from capsule.layers import Capsule, Length\n",
    "from capsule.capsulefunctions import squash, softmax, margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_timestesp = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n",
      "Setting up params\n",
      "\n",
      "max min f 10.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.05, n_timesteps=40, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      " sample length:  40.000000\n",
      " max_f: 10.000000, min_f: 0.500000\n"
     ]
    }
   ],
   "source": [
    "context = setup.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing midi-data\n",
      "\n",
      "Encoding midi-data\n",
      " 500\n",
      "> -> multi-track = True MidiFile\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  True\n"
     ]
    }
   ],
   "source": [
    "n = 500 * 1\n",
    "dim4 = True\n",
    "multiTrack = True\n",
    "reduce_dims = midi.ReduceDimsOptions.MIDIFILE # GLOBAL\n",
    "dn = 'drum_midi/'\n",
    "x_train, labels = setup.import_data(context, n, dim4=dim4, reduce_dims=reduce_dims, dirname=dn, multiTrack=multiTrack, r=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1000\n",
    "# min_f = 0\n",
    "# max_f = 3\n",
    "# x_train, params = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f,\n",
    "#     n_polyrythms=1,\n",
    "#     n_channels=3,\n",
    "#     d_phase=True,\n",
    "#     return_params=True,\n",
    "#     dim4=dim4,\n",
    "#     multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 40, 10, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 40, 10, 1), 450)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = int(x_train.shape[0] * 0.9)\n",
    "x_train.shape, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_train[m:]\n",
    "x_train = x_train[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (40, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1181029b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (40, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1181029e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['../datasets/drum_midi//Cha cha/cha cha 1.mid',\n",
       " '../datasets/drum_midi//Cha cha/cha cha 2.mid',\n",
       " '../datasets/drum_midi//Cha cha/cha cha 3.mid',\n",
       " \"../datasets/drum_midi//50Â´s Drummer MIDI Files/01 Rock'n'Roll/06 Moonglow 140BPM/05 8th Hat.mid\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot.single(x_train[0, :50,:,0])\n",
    "plot.single(x_train[1, :50,:,0])\n",
    "# plot.single(x_train[2, :50,:,0])\n",
    "labels[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_train[0].shape\n",
    "timesteps = input_shape[0]\n",
    "notes = input_shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_shape, dropout=0.1):\n",
    "    encoder_input = Input(shape=input_shape)\n",
    "    nodes = np.prod(input_shape)\n",
    "    timesteps, notes, channels = input_shape\n",
    "    \n",
    "    # Convolution\n",
    "    h = encoder_input\n",
    "    k = (2,1)\n",
    "    s = (2,1)\n",
    "    \n",
    "    h = Conv2D(32, kernel_size=k, strides=1, activation='relu', padding='valid')(h)\n",
    "    h = Conv2D(64, kernel_size=k, strides=s, activation='relu', padding='valid')(h)\n",
    "    h = Conv2D(128, kernel_size=k, strides=s, activation='relu', padding='valid')(h)\n",
    "\n",
    "    # input per note\n",
    "    note_list = Permute([2,1,3], name='input_per_note')(h)\n",
    "    \n",
    "    rnn = SimpleRNN(128, name='rnn_per_note')\n",
    "    reshape = Reshape((128,1))\n",
    "\n",
    "    n_capsules = 10\n",
    "    capsule_dim = 6\n",
    "    n_routings=3\n",
    "    share_weights=True\n",
    "    capsule = Capsule(n_capsules, capsule_dim, n_routings, share_weights)\n",
    "\n",
    "    x = Lambda(lambda layer: capsule(reshape(rnn(layer))) )\n",
    "    h_per_note = TimeDistributed(x, name='TimeDistributed_per_note')(note_list)\n",
    "    shape = K.int_shape(h_per_note)[1:]\n",
    "    h_per_note = Reshape( [notes, np.prod(shape[1:3])] )(h_per_note)\n",
    "    h_per_note = Flatten()(h_per_note)\n",
    "\n",
    "    # 'global' input\n",
    "    h = encoder_input\n",
    "    h = Reshape(input_shape[:-1])(h)\n",
    "    h = Conv1D(32, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "    h = Conv1D(64, kernel_size=2, strides=2, activation='relu', padding='valid')(h)\n",
    "    h = Conv1D(128, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "    # old layers\n",
    "#     h = Conv2D(1, kernel_size=k, strides=1, activation='relu', padding='valid')(h)\n",
    "#     shape = K.int_shape(h)[1:]\n",
    "#     h = Reshape(shape[0:2])(h) # (reduced_timesteps, notes)\n",
    "#     h = Conv1D(32, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "#     h = SimpleRNN(512)(h)\n",
    "    h = LSTM(256)(h)\n",
    "#     h = Bidirectional(LSTM(256)(h))\n",
    "    h_global = h\n",
    "    \n",
    "    h = Reshape((-1,1))(h_global) # h_global h_per_note\n",
    "#     h = Concatenate(axis=1)([h_global, h_per_note])\n",
    "\n",
    "    h = Reshape((-1,1))(h)\n",
    "    \n",
    "    n_capsules = 10\n",
    "    capsule_dim = 6\n",
    "    n_routings=3\n",
    "    share_weights=True\n",
    "    h = Capsule(n_capsules, capsule_dim, n_routings, share_weights)(h)   \n",
    "    h = Flatten()(h)\n",
    "    \n",
    "    # Z Mean, Variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(h) # , activation='relu'\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(h) # , activation='relu'\n",
    "        \n",
    "    encoder_output = [z_mean, z_log_var]\n",
    "    encoder_model = Model(encoder_input, encoder_output, name='encoder_model-')\n",
    "    print('Extra params:', [k.count_params() for k in [rnn, reshape, capsule]])\n",
    "\n",
    "    return encoder_model, encoder_input, z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights, shape = (1, 1, 60) 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/layers/core.py:642: UserWarning: `output_shape` argument not specified for layer lambda_4 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 9, 128)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights, shape = (1, 1, 60) 60\n",
      "Extra params: [32896, 0, 60]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 40, 10, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 40, 10)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 39, 32)       672         reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 19, 64)       4160        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 18, 128)      16512       conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 256)          394240      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 256, 1)       0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 256, 1)       0           reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "capsule_4 (Capsule)             (None, 10, 6)        60          reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 60)           0           capsule_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            122         flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            122         flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 415,888\n",
      "Trainable params: 415,888\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model, encoder_input, z_mean, z_log_var = encoder(input_shape)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = lambda args: models.sample(args, z_mean, z_log_var, latent_dim, epsilon_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/layers/core.py:642: UserWarning: `output_shape` argument not specified for layer lambda_5 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `[(None, 2), (None, 2)]` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "# z = Lambda(sampling)([z_mean, z_log_var])\n",
    "z_input = encoder_model(encoder_input)\n",
    "z_output = Lambda(sample_)(z_input)\n",
    "# z_output = Lambda(sampl_, output_shape=(latent_dim,))(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_decoders(output_shape):\n",
    "    # decoder_input = z_output\n",
    "    # h = decoder_input\n",
    "    # :output_shape = (timesteps, channels, channels) || (batches, filters, timesteps, channels)\n",
    "    # keras offers just Conv2DTranspose and not Conv1DTranspose\n",
    "    # - use 2D images during upsampling :: (timesteps, notes, channels) => (timesteps, notes, filters)\n",
    "    # - use 1D images to optimize reconstruction :: (timesteps, filters) => (timesteps, notes)\n",
    "    \n",
    "    # image_data_format = 'channels_last'\n",
    "    # goal shape: (timesteps, notes, channels)\n",
    "    # start with the 'reverse': lots of small imgs => few large img\n",
    "    \n",
    "    timesteps, notes, channels = output_shape\n",
    "    filters = 64\n",
    "    output_shape = (14, 14, filters)\n",
    "    output_shape = (timesteps, notes, 1)\n",
    "    \n",
    "    # keras.examples.variational_autoencoder_deconv.py\n",
    "    decoders = []\n",
    "    decoders += [ Dense(128, activation='relu') ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "    decoders += [ Dense(np.prod(output_shape), activation='relu') ]\n",
    "\n",
    "    # Convolution\n",
    "    k = (3,1) # (2,1) :: (timesteps, notes)\n",
    "    # (14, 14, filters)\n",
    "    decoders += [ Reshape(output_shape) ]\n",
    "    decoders += [ Conv2DTranspose(filters, kernel_size=k, strides=1, activation='relu', padding='same') ]\n",
    "    decoders += [ Conv2DTranspose(filters, kernel_size=k, strides=1, activation='relu', padding='same') ]\n",
    "    # (29, 29, filters)\n",
    "    k = (3,1) # (2,1) :: (timesteps, notes)\n",
    "    s = (2,1)\n",
    "    decoders += [ Conv2DTranspose(filters, kernel_size=k, strides=s, activation='relu', padding='valid') ]\n",
    "    decoders += [ Conv2D(1, kernel_size=k, strides=s, activation='sigmoid', padding='valid') ]\n",
    "    #     h = Dropout(dropout)(h) # uncomment when using larger batches\n",
    "\n",
    "#     decoders += [ Flatten()]\n",
    "#     decoders += [ Dense(np.prod(output_shape), activation='sigmoid')]\n",
    "#     decoders += [ Reshape(output_shape)]\n",
    "    return decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoders = list_decoders(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = utils.composition(decoders, z_output, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 40, 10, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_model- (Model)          [(None, 2), (None, 2 415888      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               [(None, 2), (None, 2 0           encoder_model-[1][0]             \n",
      "                                                                 encoder_model-[1][1]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          384         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 512)          66048       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          262656      dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 400)          205200      dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 40, 10, 1)    0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 40, 10, 64)   256         reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 40, 10, 64)   12352       conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 81, 10, 64)   12352       conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 40, 10, 1)    193         conv2d_transpose_9[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 975,329\n",
      "Trainable params: 975,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate VAE model\n",
    "vae_input = encoder_input\n",
    "vae_output = decoded\n",
    "vae = Model(vae_input, vae_output)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Output \"conv2d_10\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"conv2d_10\" during training.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Compute VAE loss\n",
    "def vae_loss(beta=1.):\n",
    "    # y_true, y_pred, z_mean, z_log_var, timesteps=150, notes=3, beta=1.\n",
    "    xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(vae_input), K.flatten(vae_output))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + beta * kl_loss)\n",
    "    return vae_loss\n",
    "\n",
    "vae_loss = vae_loss(beta=1)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "# vae.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 100\n",
    "params = {'batch_size': batch_size, 'return_y': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mod = 0.01\n",
    "whitening = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /Users/mark/.theano/compiledir_Darwin-17.5.0-x86_64-i386-64bit-i386-3.6.5-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25 samples, validate on 50 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: summation axis sizes unequal. x.shape is (25, 60, 10), y.shape is (25, 6, 2560).\nApply node that caused the error: BatchedDot(Reshape{3}.0, Reshape{3}.0)\nToposort index: 350\nInputs types: [TensorType(float32, 3D), TensorType(float32, 3D)]\nInputs shapes: [(25, 60, 10), (25, 6, 2560)]\nInputs strides: [(2400, 40, 4), (61440, 10240, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{5}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-ee3ce32814a5>\", line 2, in <module>\n    z_input = encoder_model(encoder_input)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/Users/mark/src/pattern-recognition/src/capsule/layers.py\", line 99, in call\n    b += K.batch_dot(outputs, hat_inputs, [2, 3])\n  File \"/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py\", line 454, in batch_dot\n    out = T.batched_tensordot(x, y, axes=axes)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: summation axis sizes unequal. x.shape is (25, 60, 10), y.shape is (25, 6, 2560).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-bee929983af4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: summation axis sizes unequal. x.shape is (25, 60, 10), y.shape is (25, 6, 2560).\nApply node that caused the error: BatchedDot(Reshape{3}.0, Reshape{3}.0)\nToposort index: 350\nInputs types: [TensorType(float32, 3D), TensorType(float32, 3D)]\nInputs shapes: [(25, 60, 10), (25, 6, 2560)]\nInputs strides: [(2400, 40, 4), (61440, 10240, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{5}(BatchedDot.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-ee3ce32814a5>\", line 2, in <module>\n    z_input = encoder_model(encoder_input)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/Users/mark/src/pattern-recognition/src/capsule/layers.py\", line 99, in call\n    b += K.batch_dot(outputs, hat_inputs, [2, 3])\n  File \"/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py\", line 454, in batch_dot\n    out = T.batched_tensordot(x, y, axes=axes)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "m = 25\n",
    "useDataGenerator = False\n",
    "# useDataGenerator = True\n",
    "\n",
    "x = x_train\n",
    "x = np.concatenate([x_train[:m] for _ in range(20)])\n",
    "\n",
    "print('batch_size =', batch_size)\n",
    "if useDataGenerator:\n",
    "    datagen = models.ImageDataGenerator(x_train, batch_size, phase_mod, whitening)\n",
    "    history = collections.defaultdict(list)\n",
    "    n_batches = datagen.__len__()\n",
    "    for e in range(epochs):\n",
    "        print('\\n[Epoch %i/%i] >>>>>>>>>' % (e, epochs))\n",
    "        for batch_i, (x_batch, y_batch) in enumerate(datagen.flow(x[:m], x[:m], batch_size)):\n",
    "            print(' Batch %i/%i' % (batch_i,n_batches))\n",
    "            x_ = x_batch\n",
    "            # x_ = datagen.shuffle_3rd_dim(x_)\n",
    "            x_ = datagen.shuffle_3rd_dim_soft(x_, rate=0.5, scale=0.1, verbose=0)\n",
    "            h = vae.fit(x_, validation_data=(x_test, None), verbose=0)\n",
    "            for k,v in h.history.items(): \n",
    "                print(' \\\\_%s' % k, [round(v_,) for v_ in v])\n",
    "                history[k].append(v)\n",
    "            if batch_i >= n_batches:\n",
    "                break\n",
    "else:\n",
    "    h = vae.fit(x[:m], epochs=epochs, validation_data=(x_test, None))\n",
    "    history = h.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = -1\n",
    "k = 10\n",
    "x = vae.predict(x_train[:100])\n",
    "plot.single(x_train[i, :50, :, 0])\n",
    "plot.single(x[i, :50, :, 0])\n",
    "plot.single(x_train[j, :50, :, 0])\n",
    "plot.single(x[j, :50, :, 0])\n",
    "plot.single(x_train[k, :50, :, 0])\n",
    "plot.single(x[k, :50, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datagen.shuffle_3rd_dim_soft(x_train[:10], mutation_rate=0.5, scale=0.5, verbose=0)\n",
    "plot.single(x_train[0,:,:,0])\n",
    "plot.single(x[0,:,:,0])\n",
    "x_ = vae.predict(x)\n",
    "plot.single(x_[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min: these pixels are 'always' active\n",
    "m = x.min(axis=0)\n",
    "plot.multi(m[:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "m = x.mean(axis=0)\n",
    "plot.single(m[:30,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder + Generator\n",
    "A model to project inputs on the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(encoder_input, z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "x_train_encoded = encoder.predict(x_train[:m], batch_size=batch_size)\n",
    "x_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = range(x_train_encoded.shape[0])\n",
    "y_test = np.concatenate([list(range(n)) for _ in range(int(m/n)+1)])[:m] / n\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_train_encoded[:, 0], x_train_encoded[:, 1], alpha=0.8, s=30) # c=y_test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], alpha=0.6, s=30) # , c=y_test\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_decoded = utils.composition(decoders, decoder_input, verbose=False)\n",
    "generator = Model(decoder_input, _decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_decoded[0].reshape(150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = 0.01\n",
    "max_y = 0.5\n",
    "plot.latent(generator, batch_size,\n",
    "       n=8,\n",
    "       m=3,\n",
    "       crop_size=30,\n",
    "       margin_top=1,\n",
    "       margin_left=1,\n",
    "       min_x=0.05,\n",
    "       max_x=0.95,\n",
    "       min_y=min_y,\n",
    "       max_y=max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y2 = max_y\n",
    "plot.latent(generator, batch_size,\n",
    "       n=8,\n",
    "       m=3,\n",
    "       crop_size=30,\n",
    "       margin_top=1,\n",
    "       margin_left=1,\n",
    "       min_x=0.05,\n",
    "       max_x=0.95,\n",
    "       min_y=min_y2,\n",
    "       max_y=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
