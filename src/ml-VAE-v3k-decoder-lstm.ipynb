{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "## NN libs\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os, numpy as np, pandas, sklearn, scipy.signal as signal\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local libs\n",
    "import config, models, setup\n",
    "import midi\n",
    "from midi import generators as g\n",
    "from utils import io, models_io, utils, plot\n",
    "from capsule.layers import Capsule, Length\n",
    "from capsule.capsulefunctions import squash, softmax, margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_timestesp = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n",
      "Setting up params\n",
      "\n",
      "max min f 10.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.05, n_timesteps=40, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      " sample length:  40.000000\n",
      " max_f: 10.000000, min_f: 0.500000\n"
     ]
    }
   ],
   "source": [
    "context = setup.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing midi-data\n",
      "\n",
      "Encoding midi-data\n",
      " 500\n",
      "> -> multi-track = True MidiFile\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  True\n"
     ]
    }
   ],
   "source": [
    "n = 500 * 1\n",
    "dim4 = True\n",
    "multiTrack = True\n",
    "reduce_dims = midi.ReduceDimsOptions.MIDIFILE # GLOBAL\n",
    "dn = 'drum_midi/'\n",
    "x_train, labels = setup.import_data(context, n, dim4=dim4, reduce_dims=reduce_dims, dirname=dn, multiTrack=multiTrack, r=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1000\n",
    "# min_f = 0\n",
    "# max_f = 3\n",
    "# x_train, params = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f,\n",
    "#     n_polyrythms=1,\n",
    "#     n_channels=3,\n",
    "#     d_phase=True,\n",
    "#     return_params=True,\n",
    "#     dim4=dim4,\n",
    "#     multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 40, 9, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 40, 9, 1), 450)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = int(x_train.shape[0] * 0.9)\n",
    "x_train.shape, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_train[m:]\n",
    "x_train = x_train[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (40, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1231abe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (40, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABuCAYAAAAH1fk7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAACAhJREFUeJzt3V+opHUdx/H3p/1T+QdK3BZRtzSFWKLMPSsFIhYk2o0FEgqBd1uRUBdB1k0WCBX07yKKrUwvMpPKUpBSSLAr85xac00rsw1dzG0JyW4S9dvFPFvTes7MnD3z7Dy/9f2Cw3nmmdl5Pvyemc8+5/kzk6pCktSOVy06gCRpfSxuSWqMxS1JjbG4JakxFrckNcbilqTGWNyS1BiLW5IaY3FLUmM29/GkSSZejnneeedNfY6TTjpp4v1btmxZXyj1bmVlZeL909b7tHUOG1/v0zLCMHJqvjb62oT+O+nAgQMcPnw4szw2s1zynuRy4OvAJuA7VfWFKY+f+KR33XXX1GXu3r174v3bt2+f+hw6vpLJr7lp633aOoeNr/dpGWEYOTVfG31tQv+dtLS0xPLy8kzFPXVXSZJNwDeAK4CdwDVJdm4ooSTpmM2yj/si4PGqeqKqngduA67sN5YkaS2zFPeZwJNjt5/q5kmSFmBuByeT7AH2zOv5JEmrm6W4DwJnj90+q5v3f6pqL7AXph+clCQdu1l2lTwInJ/knCRbgauBO/uNJUlay9Qt7qp6Icl1wC8YnQ54U1U9Munf7Nq1i+Xl5TlFlObHb3x6ZTrR1vtM+7ir6m7g7p6zSJJm4CXvktQYi1uSGmNxS1JjLG5JaozFLUmNsbglqTEWtyQ1ppcvUtAr04l2kYNOHC18Hvd6uMUtSY2xuCWpMRa3JDXG4pakxljcktQYi1uSGmNxS1JjPI+7ARs9B3Xa+acwn3NQW8mp+Zm2zmHj6911/nJucUtSYyxuSWqMxS1JjbG4JakxFrckNcbilqTGWNyS1BiLW5Ia08sFOCsrKxNPzG/tQ8sXrZUvKGgh5/G4YAReOa/PFtY5tJNzVm5xS1JjLG5JaozFLUmNsbglqTEWtyQ1xuKWpMZY3JLUmF7O4961axfLy8t9PLW0ISfa+byL5hcpLMZMxZ3kAPAc8CLwQlUt9RlKkrS29Wxxv7uqDveWRJI0E/dxS1JjZi3uAu5JspJkT5+BJEmTzbqr5OKqOpjkDcC9SR6rqvvHH9AV+h6AHTt2zDmmJOmImba4q+pg9/sQcAdw0SqP2VtVS1W1tG3btvmmlCT919TiTnJyklOPTAOXAfv7DiZJWt0su0q2A3d052tuBm6tqp/3mkqStKapxV1VTwBvX8+T+kUK8zXtIgc/+H92fpGCTgSeDihJjbG4JakxFrckNcbilqTGWNyS1BiLW5IaY3FLUmP8IoUG+OH/8+NYzpfjuRhucUtSYyxuSWqMxS1JjbG4JakxFrckNcbilqTGWNyS1BiLW5IaY3FLUmMsbklqjMUtSY2xuCWpMRa3JDXG4pakxljcktQYi1uSGpM+Pgg9yd+Bv47NOh04PPcFzV8LOVvICOacN3PO1xBzvrGqts3ywF6K+2ULSZaraqn3BW1QCzlbyAjmnDdzzlcrOdfirhJJaozFLUmNOV7Fvfc4LWejWsjZQkYw57yZc75aybmq47KPW5I0P+4qkaTG9FrcSS5P8ockjye5vs9lbUSSA0keTrIvyfKi8xyR5KYkh5LsH5t3WpJ7k/yp+/36RWbsMq2W84YkB7sx3ZfkfYvM2GU6O8l9SX6f5JEkH+/mD2ZMJ2Qc1HgmeU2SXyd5qMv5uW7+OUke6N7zP0yydaA5b07yl7HxvGCROdetqnr5ATYBfwbOBbYCDwE7+1reBrMeAE5fdI5Vcl0CXAjsH5v3JeD6bvp64IsDzXkD8MlFZzsq5xnAhd30qcAfgZ1DGtMJGQc1nkCAU7rpLcADwDuB24Gru/nfAj460Jw3A1ctehyP9afPLe6LgMer6omqeh64Dbiyx+WdcKrqfuAfR82+Erilm74FeP9xDbWKNXIOTlU9XVW/6aafAx4FzmRAYzoh46DUyL+6m1u6nwLeA/yom7/w1+eEnE3rs7jPBJ4cu/0UA3wBdgq4J8lKkj2LDjPF9qp6upv+G7B9kWGmuC7J77pdKQvfpTMuyZuAdzDaAhvkmB6VEQY2nkk2JdkHHALuZfQX9rNV9UL3kEG854/OWVVHxvPGbjy/muTVC4y4bh6cHLm4qi4ErgA+luSSRQeaRY3+/hvq1sM3gTcDFwBPA19ebJz/SXIK8GPgE1X1z/H7hjKmq2Qc3HhW1YtVdQFwFqO/sN+y4EirOjpnkrcCn2aUdzdwGvCpBUZctz6L+yBw9tjts7p5g1NVB7vfh4A7GL0Ih+qZJGcAdL8PLTjPqqrqme4N8xLwbQYypkm2MCrE71fVT7rZgxrT1TIOdTwBqupZ4D7gXcDrkmzu7hrUe34s5+XdLqmqqn8D32NA4zmLPov7QeD87ijzVuBq4M4el3dMkpyc5NQj08BlwP7J/2qh7gSu7aavBX62wCxrOlKEnQ8wgDFNEuC7wKNV9ZWxuwYzpmtlHNp4JtmW5HXd9GuB9zLaH38fcFX3sIW/PtfI+djYf9RhtB9+4a/P9ej1ApzulKWvMTrD5KaqurG3hR2jJOcy2soG2AzcOpScSX4AXMrok8yeAT4L/JTRkfsdjD6B8YNVtdADg2vkvJTRn/XF6KydD4/tR16IJBcDvwIeBl7qZn+G0T7kQYzphIzXMKDxTPI2RgcfNzHaALy9qj7fvZ9uY7T74bfAh7qt2qHl/CWwjdFZJ/uAj4wdxBw8r5yUpMZ4cFKSGmNxS1JjLG5JaozFLUmNsbglqTEWtyQ1xuKWpMZY3JLUmP8ATfU9y0FnGckAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12322ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['../datasets/drum_midi//Cha cha/cha cha 1.mid',\n",
       " '../datasets/drum_midi//Cha cha/cha cha 2.mid',\n",
       " '../datasets/drum_midi//Cha cha/cha cha 3.mid',\n",
       " \"../datasets/drum_midi//50´s Drummer MIDI Files/01 Rock'n'Roll/06 Moonglow 140BPM/05 8th Hat.mid\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot.single(x_train[0, :50,:,0])\n",
    "plot.single(x_train[1, :50,:,0])\n",
    "# plot.single(x_train[2, :50,:,0])\n",
    "labels[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 9, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_train[0].shape\n",
    "timesteps = input_shape[0]\n",
    "notes = input_shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 20\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_shape, dropout=0.1):\n",
    "    encoder_input = Input(shape=input_shape)\n",
    "    nodes = np.prod(input_shape)\n",
    "    timesteps, notes, channels = input_shape\n",
    "    \n",
    "    # Convolution\n",
    "    h = encoder_input\n",
    "    k = (2,1)\n",
    "    s = (2,1)\n",
    "    \n",
    "    h = Conv2D(32, kernel_size=k, strides=1, activation='relu', padding='valid')(h)\n",
    "    h = Conv2D(64, kernel_size=k, strides=s, activation='relu', padding='valid')(h)\n",
    "    h = Conv2D(128, kernel_size=k, strides=s, activation='relu', padding='valid')(h)\n",
    "    \n",
    "    # input per note\n",
    "    note_list = Permute([2,1,3], name='input_per_note')(h)\n",
    "    \n",
    "    rnn = SimpleRNN(128, name='rnn_per_note')\n",
    "    reshape = Reshape((128,1))\n",
    "\n",
    "    n_capsules = 10\n",
    "    capsule_dim = 6\n",
    "    n_routings=3\n",
    "    share_weights=True\n",
    "    capsule = Capsule(n_capsules, capsule_dim, n_routings, share_weights)\n",
    "\n",
    "    x = Lambda(lambda layer: capsule(reshape(rnn(layer))) )\n",
    "    h_per_note = TimeDistributed(x, name='TimeDistributed_per_note')(note_list)\n",
    "    shape = K.int_shape(h_per_note)[1:]\n",
    "    h_per_note = Reshape( [notes, np.prod(shape[1:3])] )(h_per_note)\n",
    "    h_per_note = Flatten()(h_per_note)\n",
    "\n",
    "    # 'global' input\n",
    "    h = encoder_input\n",
    "    h = Reshape(input_shape[:-1])(h)\n",
    "    h = Conv1D(32, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "    h = Conv1D(64, kernel_size=2, strides=2, activation='relu', padding='valid')(h)\n",
    "    h = Conv1D(128, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "    # old layers\n",
    "#     h = Conv2D(1, kernel_size=k, strides=1, activation='relu', padding='valid')(h)\n",
    "#     shape = K.int_shape(h)[1:]\n",
    "#     h = Reshape(shape[0:2])(h) # (reduced_timesteps, notes)\n",
    "#     h = Conv1D(32, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "    h = SimpleRNN(128)(h)\n",
    "#     h = LSTM(256)(h)\n",
    "#     h = Bidirectional(LSTM(256)(h))\n",
    "    h_global = h\n",
    "    \n",
    "    h = Reshape((-1,1))(h_global) # h_global h_per_note\n",
    "#     h = Concatenate(axis=1)([h_global, h_per_note])\n",
    "\n",
    "#     h = Reshape((-1,1))(h)\n",
    "    \n",
    "    n_capsules = 10\n",
    "    capsule_dim = 6\n",
    "    n_routings=3\n",
    "    share_weights=True\n",
    "    h = Capsule(n_capsules, capsule_dim, n_routings, share_weights)(h)   \n",
    "    h = Flatten()(h)\n",
    "    \n",
    "    # Z Mean, Variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(h) # , activation='relu'\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(h) # , activation='relu'\n",
    "        \n",
    "    encoder_output = [z_mean, z_log_var]\n",
    "    encoder_model = Model(encoder_input, encoder_output, name='encoder_model-')\n",
    "    print('Extra params:', [k.count_params() for k in [rnn, reshape, capsule]])\n",
    "\n",
    "    return encoder_model, encoder_input, z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights, shape = (1, 1, 60) 60\n",
      "shared weights, shape = (1, 1, 60) 60\n",
      "Extra params: [32896, 0, 60]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40, 9, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 40, 9)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 39, 32)       608         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 19, 64)       4160        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 18, 128)      16512       conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)        (None, 128)          32896       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1)       0           simple_rnn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "capsule_2 (Capsule)             (None, 10, 6)        60          reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 60)           0           capsule_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 20)           1220        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 20)           1220        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 56,676\n",
      "Trainable params: 56,676\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model, encoder_input, z_mean, z_log_var = encoder(input_shape)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = lambda args: models.sample(args, z_mean, z_log_var, latent_dim, epsilon_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = Lambda(sampling)([z_mean, z_log_var])\n",
    "z_input = encoder_model(encoder_input)\n",
    "z_output = Lambda(sample_)(z_input)\n",
    "# z_output = Lambda(sampl_, output_shape=(latent_dim,))(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_decoders(output_shape):\n",
    "    # decoder_input = z_output\n",
    "    # h = decoder_input\n",
    "    # :output_shape = (timesteps, channels, channels) || (batches, filters, timesteps, channels)\n",
    "    # keras offers just Conv2DTranspose and not Conv1DTranspose\n",
    "    # - use 2D images during upsampling :: (timesteps, notes, channels) => (timesteps, notes, filters)\n",
    "    # - use 1D images to optimize reconstruction :: (timesteps, filters) => (timesteps, notes)\n",
    "    \n",
    "    # image_data_format = 'channels_last'\n",
    "    # goal shape: (timesteps, notes, channels)\n",
    "    # start with the 'reverse': lots of small imgs => few large img\n",
    "    \n",
    "    timesteps, notes, channels = output_shape\n",
    "    filters = 64\n",
    "    output_shape = (14, 14, filters)\n",
    "    output_shape = (timesteps, notes, 1)\n",
    "    \n",
    "    # keras.examples.variational_autoencoder_deconv.py\n",
    "    decoders = []\n",
    "    decoders += [ Dense(128, activation='relu') ]\n",
    "    # add a bypass layer\n",
    "    w = 256\n",
    "    decoders += [ Dense(w, activation='relu') ]\n",
    "    extra_decoders = []\n",
    "    for _ in range(5):\n",
    "        extra_decoders += [ Dense(w, activation='relu', bias_initializer='zeros') ]\n",
    "\n",
    "    extra_ = Lambda(lambda layer: utils.composition(extra_decoders, layer))\n",
    "    decoders += [ Lambda(lambda layer: Add()([layer, extra_(layer)])) ]\n",
    "    \n",
    "    decoders += [ BatchNormalization(momentum=0.1) ]\n",
    "\n",
    "    # Shared conv layer\n",
    "    dim1, dim2, filters = int(timesteps/2), notes*2, 16\n",
    "    print('dim1: %i dim2: %i filters: %i' % (dim1, dim2, filters))\n",
    "    decoders += [ Dense(dim1*dim2, activation='relu') ]\n",
    "    \n",
    "    decoders += [ BatchNormalization(momentum=0.1) ]\n",
    "    \n",
    "    decoders += [ Reshape((dim1,dim2,1,1)) ]\n",
    "    conv = Conv2DTranspose(filters, kernel_size=(2,1), activation='relu', padding='same')\n",
    "    decoders += [ TimeDistributed(conv) ]\n",
    "    decoders += [ Reshape((dim1, dim2, filters)) ]\n",
    "    decoders += [ Reshape((dim1, dim2*filters)) ]\n",
    "    \n",
    "    decoders += [ LSTM(dim2*filters, return_sequences=True) ]\n",
    "    # shape = (dim1, dim2*filters) = (16, 256)\n",
    "    \n",
    "    decoders += [ Reshape((dim1, dim2, filters))]\n",
    "    decoders += [ Conv2DTranspose(filters, kernel_size=(2,1), strides=(2,1), activation='relu', padding='valid') ]  \n",
    "    \n",
    "    decoders += [ BatchNormalization() ]\n",
    "\n",
    "    \n",
    "#     decoders += [ Reshape((-1, 1))]\n",
    "    decoders += [ Conv2D(1, kernel_size=(2,1), strides=(1,2), activation='sigmoid', padding='same') ]\n",
    "\n",
    "    # Denoising layer\n",
    "    # TODO Bidirectional\n",
    "#     decoders += [ Reshape((timesteps, notes*filters)) ]\n",
    "#     decoders += [ LSTM(notes, return_sequences=True, activation='sigmoid') ]\n",
    "\n",
    "#     decoders += [ Reshape(output_shape) ]\n",
    "\n",
    "#     decoders += [ (lambda layer: dense(layer)) ]\n",
    "    # activation: LeakyReLU(0.2)\n",
    "#     decoders += [ RepeatVector(timesteps) ]\n",
    "\n",
    "#     w = 256\n",
    "#     dense1 = Dense(w, activation='relu')\n",
    "#     dense2 = Dense(w, activation='relu')\n",
    "#     dense3 = Dense(w, activation='relu')\n",
    "#     seq = RepeatVector(timesteps)\n",
    "#     lstm = LSTM(w, return_sequences=True)\n",
    "#     rnn = Lambda(lambda layer:\n",
    "#                   lstm(seq(dense3(layer)), initial_state=[dense1(layer), dense2(layer)])\n",
    "#                  )\n",
    "#     decoders += [ rnn ]\n",
    "#     decoders += [ TimeDistributed(Dense(notes, activation='sigmoid')) ]\n",
    "    \n",
    "#     decoders += [ LSTM(notes, return_sequences='True') ]\n",
    "#     decoders += [ Dense(512, activation='relu') ]\n",
    "#     decoders += [ Dense(np.prod(output_shape), activation='relu') ]\n",
    "#     decoders += [ BatchNormalization() ]\n",
    "\n",
    "#     decoders += [ TimeDistributed(Bidirectional(LSTM(32))) ]\n",
    "#     decoders += [ Flatten() ]\n",
    "#     decoders += [ Dense(np.prod(output_shape), activation='relu') ]\n",
    "\n",
    "#     decoders += [ Reshape(output_shape) ]\n",
    "\n",
    "    # TimeDistributed: apply the same layer to every timestep\n",
    "    # LSTM: 'remember' previous timesteps\n",
    "    # Bidirectional: 'remember' previous and next timesteps\n",
    "#     decoders += [ TimeDistributed(Bidirectional(LSTM(32, return_sequences=True))) ]\n",
    "\n",
    "#     decoders += [ Flatten()]\n",
    "#     decoders += [ Dense(np.prod(output_shape), activation='sigmoid')]\n",
    "#     decoders += [ Reshape(output_shape)]\n",
    "    return decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim1: 20 dim2: 18 filters: 16\n"
     ]
    }
   ],
   "source": [
    "decoders = list_decoders(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = utils.composition(decoders, z_output, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40, 9, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_model- (Model)          [(None, 20), (None,  56676       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 20)           0           encoder_model-[1][0]             \n",
      "                                                                 encoder_model-[1][1]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          2688        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          33024       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 360)          92520       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 360)          1440        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 20, 18, 1, 1) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 20, 18, 1, 16 48          reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 20, 18, 16)   0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 20, 288)      0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 20, 288)      664704      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 20, 18, 16)   0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 40, 18, 16)   528         reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 40, 18, 16)   64          conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 40, 9, 1)     33          batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 852,749\n",
      "Trainable params: 851,485\n",
      "Non-trainable params: 1,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate VAE model\n",
    "vae_input = encoder_input\n",
    "vae_output = decoded\n",
    "vae = Model(vae_input, vae_output)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Output \"conv2d_4\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"conv2d_4\" during training.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Compute VAE loss\n",
    "def vae_loss(beta=1.):\n",
    "#     beta = ((1.0 - tf.pow(hparams.beta_rate, tf.to_float(self.global_step)))\n",
    "#             * hparams.max_beta)\n",
    "#     self.loss = tf.reduce_mean(r_loss) + beta * tf.reduce_mean(kl_cost)\n",
    "    # y_true, y_pred, z_mean, z_log_var, timesteps=150, notes=3, beta=1.\n",
    "    xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(vae_input), K.flatten(vae_output))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + beta * kl_loss)\n",
    "    return vae_loss\n",
    "\n",
    "vae_loss = vae_loss(beta=1)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "# vae.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 25\n",
    "params = {'batch_size': batch_size, 'return_y': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mod = 0.01\n",
    "whitening = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (2500, 40, 9, 1)\n",
      "batch_size = 100\n",
      "\n",
      "[Epoch 0/25] >>>>>>>>>\n",
      " Batch 0/4\n",
      " \\_val_loss [125.0]\n",
      " \\_loss [175.0]\n",
      " Batch 1/4\n",
      " \\_val_loss [103.0]\n",
      " \\_loss [92.0]\n",
      " Batch 2/4\n",
      " \\_val_loss [89.0]\n",
      " \\_loss [79.0]\n",
      " Batch 3/4\n",
      " \\_val_loss [91.0]\n",
      " \\_loss [76.0]\n",
      " Batch 4/4\n",
      " \\_val_loss [90.0]\n",
      " \\_loss [74.0]\n",
      "\n",
      "[Epoch 1/25] >>>>>>>>>\n",
      " Batch 0/4\n",
      " \\_val_loss [85.0]\n",
      " \\_loss [72.0]\n",
      " Batch 1/4\n",
      " \\_val_loss [88.0]\n",
      " \\_loss [71.0]\n",
      " Batch 2/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-91fc00baee4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# x_ = datagen.shuffle_3rd_dim(x_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_3rd_dim_soft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' \\\\_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = 25\n",
    "useDataGenerator = False\n",
    "useDataGenerator = True\n",
    "\n",
    "x = x_train\n",
    "x = np.concatenate([x_train[:m] for _ in range(100)])\n",
    "print('x:', x.shape)\n",
    "\n",
    "print('batch_size =', batch_size)\n",
    "if useDataGenerator:\n",
    "    datagen = models.ImageDataGenerator(x_train, batch_size, phase_mod, whitening)\n",
    "    history = collections.defaultdict(list)\n",
    "    n_batches = datagen.__len__()\n",
    "    for e in range(epochs):\n",
    "        print('\\n[Epoch %i/%i] >>>>>>>>>' % (e, epochs))\n",
    "        for batch_i, (x_batch, y_batch) in enumerate(datagen.flow(x, x, batch_size)):\n",
    "            print(' Batch %i/%i' % (batch_i,n_batches))\n",
    "            x_ = x_batch\n",
    "            # x_ = datagen.shuffle_3rd_dim(x_)\n",
    "            x_ = datagen.shuffle_3rd_dim_soft(x_, rate=0.5, scale=0.1, verbose=0)\n",
    "            h = vae.fit(x_, validation_data=(x_test, None), verbose=0)\n",
    "            for k,v in h.history.items(): \n",
    "                print(' \\\\_%s' % k, [round(v_,) for v_ in v])\n",
    "                history[k].append(v)\n",
    "            if batch_i >= n_batches:\n",
    "                break\n",
    "else:\n",
    "    h = vae.fit(x, epochs=epochs, validation_data=(x_test, None))\n",
    "    history = h.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "k = -1\n",
    "x = vae.predict(x_train[:100])\n",
    "plot.single(x_train[i, :50, :, 0])\n",
    "plot.single(x[i, :50, :, 0])\n",
    "plot.single(x_train[j, :50, :, 0])\n",
    "plot.single(x[j, :50, :, 0])\n",
    "plot.single(x_train[k, :50, :, 0])\n",
    "plot.single(x[k, :50, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datagen.shuffle_3rd_dim_soft(x_train[:10], rate=1, intensity=2, scale=1, verbose=1)\n",
    "i = 0\n",
    "plot.single(x_train[i,:,:,0])\n",
    "plot.single(x[i,:,:,0])\n",
    "x_ = vae.predict(x)\n",
    "plot.single(x_[i,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min: these pixels are 'always' active\n",
    "m = x.min(axis=0)\n",
    "plot.multi(m[:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "m = x.mean(axis=0)\n",
    "plot.single(m[:30,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder + Generator\n",
    "A model to project inputs on the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(encoder_input, z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "x_train_encoded = encoder.predict(x_train[:m], batch_size=batch_size)\n",
    "x_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = range(x_train_encoded.shape[0])\n",
    "y_test = np.concatenate([list(range(n)) for _ in range(int(m/n)+1)])[:m] / n\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_train_encoded[:, 0], x_train_encoded[:, 1], alpha=0.8, s=30) # c=y_test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], alpha=0.6, s=30) # , c=y_test\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_decoded = utils.composition(decoders, decoder_input, verbose=False)\n",
    "generator = Model(decoder_input, _decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_decoded[0].reshape(150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = 0.01\n",
    "max_y = 0.5\n",
    "plot.latent(generator, batch_size, latent_dim,\n",
    "       n=8,\n",
    "       m=3,\n",
    "       crop_size=30,\n",
    "       margin_top=1,\n",
    "       margin_left=1,\n",
    "       min_x=0.05,\n",
    "       max_x=0.95,\n",
    "       min_y=min_y,\n",
    "       max_y=max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y2 = max_y\n",
    "plot.latent(generator, batch_size, latent_dim,\n",
    "       n=8,\n",
    "       m=3,\n",
    "       crop_size=30,\n",
    "       margin_top=1,\n",
    "       margin_left=1,\n",
    "       min_x=0.05,\n",
    "       max_x=0.95,\n",
    "       min_y=min_y2,\n",
    "       max_y=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
