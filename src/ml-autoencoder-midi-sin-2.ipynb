{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os, numpy as np, pandas, sklearn\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## NN libs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Input, Dense, Activation, Conv1D, Conv2D, Dropout, Flatten\n",
    "from keras.layers import Conv2DTranspose, Reshape, MaxPooling2D, UpSampling2D, UpSampling1D, MaxPooling1D\n",
    "from keras.layers import LocallyConnected1D, LocallyConnected2D\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# local libs\n",
    "import config, models, functions\n",
    "from data import data, midi, midi_generators as g\n",
    "from utils import io, models_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.1\n",
      " >> Context(max_t=10.0, dt=0.02, n_instances=500, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n"
     ]
    }
   ],
   "source": [
    "context = data.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = (config.dataset_dir + '4-floor-120bpm.mid')\n",
    "# mid = io.import_midifile(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a generator\n",
    "\n",
    "1. What is the least amount of 'hidden' nodes needed to learn a straight rythm (e.g. 8th notes with different frequencies)\n",
    "2. Can we create a model of a generic function sin(2 pi f t + phase)\n",
    "    - using x: t -> y: sin(2p t)\n",
    "    - using x: [f, t, phase] -> y: sin(2p f t + phase)\n",
    "    - using x: sin([t1, t2, t3) -> y: [f, t, phase]\n",
    "        - such a model should be able to learn complex patterns, such as sin(f1+p1) + sin(f2+p2) + sin(f3+p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  min_f < max_f\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  9.996875000000003\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  9.996875\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.006250000000003\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.011458333333325\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.03541666666667\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  9.996874999999978\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.008333333333324\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.005208333333318\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  9.999999999999991\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  9.99270833333332\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.007291666666644\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.021874999999973\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  9.991666666666658\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.008333333333336\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.009374999999991\n",
      " |>  500\n",
      "WARNING type not == 0\n",
      "WARNING type not == 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5845a12a70b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmin_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# x_train = np.zeros([10,100,127])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/pattern-recognition/src/data/midi_generators.py\u001b[0m in \u001b[0;36mgen_data\u001b[0;34m(c, n, fs, max_f, min_f)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_f\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_f\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmin_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     midis = [\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     ]\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/pattern-recognition/src/data/midi_generators.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_f\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_f\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmin_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     midis = [\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     ]\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/pattern-recognition/src/data/midi.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(c, midi, stretch)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# # prevent too high i due to rounding errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# if i == c.n_instances: i -= 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;31m# matrix[i, ] = matrix[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# result = combine_vectors(matrix[i], vector)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/pattern-recognition/src/data/midi.py\u001b[0m in \u001b[0;36mencode_msg\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# ignore msg.velocity for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mnotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mnotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# for each instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/pattern-recognition/src/data/midi.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, array)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# note: function default args are evaluated once, before runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_NOTES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "max_f = 15\n",
    "min_f = 10\n",
    "x_train = g.gen_data(context, n, max_f=max_f, min_f=min_f)\n",
    "# x_train = np.zeros([10,100,127])\n",
    "y_train = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train[0,:50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [sum(x) for x in x_train]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train\n",
    "n_samples = x_train[0]\n",
    "input_shape = x_train.shape[1:] # shape of a single sample\n",
    "output_shape = y_train.shape[1:]\n",
    "# output_length = y_train.shape[1]\n",
    "# output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "hidden_layer_length = 50\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# functional syntax: lambda x: lambda y: z\n",
    "def encoder(input_shape, output_length, dropout=0.10):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(output_length * 2, activation='relu')(x)    \n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(output_length * 2, activation='sigmoid')(x)\n",
    "    x = Dense(output_length, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "#     x = Dense(output_length, activation='relu', activity_regularizer=regularizers.l1(10e-5))(x)\n",
    "    #     model.add(Dropout(dropout))    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def decoder(input_length, output_shape, dropout=0.10):\n",
    "    input_layer = Input(shape=(input_length,))\n",
    "    x = input_layer\n",
    "    shape = output_shape\n",
    "    # shape = (10,100) # increase n dimensions\n",
    "    \n",
    "    x = Dense(np.prod(shape), activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(np.prod(shape), activation='tanh')(x)\n",
    "    x = Dense(np.prod(shape), activation='relu')(x) # 4*4*8 = 128\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Reshape(shape)(x)\n",
    "#     x = UpSampling1D(10)(x)\n",
    "    # make sure the conv layer increases the amount of dimensions\n",
    "#     dims = keras.backend.int_shape(x)[1:]\n",
    "#     n_steps = output_shape[0]\n",
    "#     n_output_timesteps = output_shape[1]\n",
    "#     filters = n_output_timesteps\n",
    "#     conv_amt = 2\n",
    "#     print('__+++==', n_output_timesteps)\n",
    "#     x = Conv1D(filters, kernel_size=4, strides=2, activation='relu')(x) # 50,100\n",
    "\n",
    "    dims = keras.backend.int_shape(x)[1:]\n",
    "#     x = UpSampling1D(dims[0] * 2)(x)\n",
    "#     x = Dense(output_shape[1], activation='relu')(x)\n",
    "    #     x = LocallyConnected1D(output_shape[1], kernel_size=1, activation='relu')(x)\n",
    "    # x = Dense(output_length, activation='softmax')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    #     model.add(Dropout(dropout))\n",
    "    return model\n",
    "\n",
    "\n",
    "def autoencoder(input_shape, output_shape, hidden_layer_length=10, dropout=0.10, verbose=False):\n",
    "    input_ = Input(shape=input_shape)\n",
    "#     reducer = resolution_reducer(input_shape,1)\n",
    "#     if verbose:\n",
    "#         reducer.summary()\n",
    "#     input_shape = reducer.output_shape[1:]\n",
    "    encode = encoder(input_shape, hidden_layer_length, dropout)\n",
    "    if verbose:\n",
    "        encode.summary()\n",
    "    decode = decoder(hidden_layer_length, output_shape, dropout)\n",
    "    if verbose:\n",
    "        decode.summary()\n",
    "    model = Model(input_, decode(encode(input_)))\n",
    "    return encode, decode, reducer, model\n",
    "\n",
    "dropout = 0.1\n",
    "encoder, decoder, reducer, auto = autoencoder(input_shape, output_shape, hidden_layer_length, dropout, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy','mse','mae']\n",
    "loss = 'binary_crossentropy'# binary_crossentropy categorical_crossentropy\n",
    "optimizer = 'adadelta'\n",
    "auto.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = auto.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[TensorBoard(log_dir=config.tmp_log_dir)])\n",
    "history = auto.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_log_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylim(ymin=0, ymax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid1 = g.render_midi(context, f=2)\n",
    "mid2 = g.render_midi(context, f=3)\n",
    "x_test = np.stack([midi.encode(context, m) for m in [mid1,mid2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxx = np.maximum(latent[0],latent[1])\n",
    "# maxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays = decoder.predict(np.stack([latent[1]]))\n",
    "arrays = auto.predict(x_train[:1])\n",
    "arrays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arrays[0,:50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = midi.decode_track(context, arrays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = config.export_dir\n",
    "io.export_midifile(mid1, dn + 'mid1.mid')\n",
    "# io.export_midifile(mid2, dn + 'mid2.mid')\n",
    "io.export_midifile(mid, dn + 'mid_generated.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
