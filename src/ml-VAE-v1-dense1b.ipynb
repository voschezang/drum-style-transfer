{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os, numpy as np, pandas, sklearn, scipy.signal as signal\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## NN libs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras import backend as K, metrics\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Input, Dense, Activation, Conv1D, Conv2D, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2DTranspose, Reshape, MaxPooling2D, UpSampling2D, UpSampling1D, MaxPooling1D\n",
    "from keras.layers import LocallyConnected1D, LocallyConnected2D\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# local libs\n",
    "import config, models, functions\n",
    "from data import data, midi, midi_generators as g\n",
    "from utils import io, models_io, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.3333333333333333\n",
      " >> Context(max_t=3.0, dt=0.02, n_instances=150, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.3333333333333333\n",
      " >> Context(max_t=3.0, dt=0.02, n_instances=150, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Importing midi-data\n",
      "\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/01 16th Snare.mid\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/01 8th Cym.mid\n",
      "\n",
      "Encoding midi-data\n",
      " [<midi file '../datasets/examples/01 16th Snare.mid' type 0, 1 tracks, 182 messages>, <midi file '../datasets/examples/01 8th Cym.mid' type 0, 1 tracks, 68 messages>]\n",
      "> -> multi-track = False\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.994791666666667\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9947916666666665\n",
      " |>  150\n"
     ]
    }
   ],
   "source": [
    "context = data.init()\n",
    "n = 2\n",
    "multiTrack = False\n",
    "context, x_train, labels = data.import_data(data.init(), n, multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.00104166666667\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.001041666666666\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9937500000000017\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.99791666666667\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9916666666666685\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906250000000014\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0041666666666687\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0000000000000027\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.996875000000002\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9947916666666683\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906250000000036\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0031250000000025\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.017708333333335\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0083333333333355\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9979166666666646\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.005208333333333\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.997916666666666\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.994791666666666\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.000000000000001\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9947916666666647\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9937500000000026\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.000000000000002\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0218749999999996\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0062499999999996\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0177083333333368\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.994791666666667\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9968750000000024\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906249999999983\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9979166666666646\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9979166666666686\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9999999999999987\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9999999999999982\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0270833333333353\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906249999999988\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0187500000000016\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9927083333333337\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.995833333333335\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.995833333333332\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9999999999999996\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.005208333333332\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.995833333333332\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906250000000023\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.997916666666666\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0125000000000037\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906250000000014\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9937500000000026\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0062500000000023\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.001041666666666\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.993750000000001\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0010416666666666\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9947916666666714\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.002083333333335\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9916666666666663\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9927083333333333\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9916666666666694\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0302083333333356\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.995833333333336\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9916666666666685\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.003124999999999\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.99375\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9979166666666712\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.018750000000003\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.011458333333333\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.000000000000001\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9937500000000004\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.008333333333334\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.002083333333334\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.995833333333333\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9937500000000004\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0010416666666693\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.993750000000006\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.994791666666668\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.993750000000001\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9968749999999997\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906250000000005\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0010416666666697\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9937500000000017\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0062500000000023\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.997916666666667\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0031250000000043\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.017708333333333\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9958333333333313\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.015625000000004\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.004166666666664\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9989583333333343\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.993750000000004\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9979166666666694\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.997916666666667\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.015625000000005\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9958333333333345\n",
      " |>  150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.001041666666667\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.996874999999998\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0166666666666675\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.0187500000000007\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.002083333333332\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9906250000000023\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9989583333333343\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.9916666666666685\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  3.000000000000001\n",
      " |>  150\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.993750000000002\n",
      " |>  150\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "min_f = 3\n",
    "max_f = 20\n",
    "# x_train = g.gen_data(context, n, max_f=max_f, min_f=min_f)\n",
    "x_train = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f, multiTrack=multiTrack)\n",
    "y_train = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 150, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1171539e8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11712a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train[0,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 150, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = x_train[0]\n",
    "input_shape = x_train.shape[1:] # shape of a single sample\n",
    "output_shape = y_train.shape[1:] # shape of a single sample\n",
    "# output_length = y_train.shape[1:][0]\n",
    "hidden_layer_length = 150\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = x_train.shape[-1]\n",
    "num_decoder_tokens = y_train.shape[-1]\n",
    "# latent_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "def sampling(args, batch_size, latent_dim):\n",
    "    # :args = 2 keras layers\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sampling() missing 2 required positional arguments: 'batch_size' and 'latent_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-58e66bb4e2a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-58e66bb4e2a8>\u001b[0m in \u001b[0;36mautoencoder\u001b[0;34m(input_shape, output_shape, hidden_layer_length, dropout, verbose)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mencode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-58e66bb4e2a8>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(input_shape, output_length, dropout)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# note that \"output_shape\" isn't necessary with the TensorFlow backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_sigma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sampling() missing 2 required positional arguments: 'batch_size' and 'latent_dim'"
     ]
    }
   ],
   "source": [
    "k_reg = regularizers.l2(0.01) # 10e-5\n",
    "# b_reg = regularizers.l1(0.01)\n",
    "a_reg = regularizers.l1(0.01) # 10e-5\n",
    "\n",
    "def encoder(input_shape, output_length, dropout=0.10):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    x = Flatten()(x)\n",
    "#     x = Dense(150, activation='relu')(x)\n",
    "    \n",
    "    intermediate_dim = 100\n",
    "    latent_dim = 100\n",
    "    \n",
    "    h = Dense(intermediate_dim, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    # so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "    \n",
    "    x = Dense(output_length, activation='relu')(x)\n",
    "#     x = Dense(output_length, activation='relu', activity_regularizer=regularizers.l1(10e-5))(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def decoder(input_length, output_shape, dropout=0.10):\n",
    "    input_layer = Input(shape=(input_length,))\n",
    "    x = input_layer\n",
    "    shape = output_shape\n",
    "    # shape = (10,100) # increase n dimensions\n",
    "    \n",
    "    intermediate_dim = 100\n",
    "    latent_dim = 100\n",
    "    \n",
    "    decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "    decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "    h_decoded = decoder_h(z)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "    \n",
    "    \n",
    "    x = Dense(150, activation='relu')(x)\n",
    "#     x = Dense(150, activation='relu')(x)    \n",
    "\n",
    "    x = Dense(np.prod(shape), activation='sigmoid')(x)\n",
    "    x = Reshape(shape)(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def autoencoder(input_shape, output_shape, hidden_layer_length=10, dropout=0.10, verbose=False):\n",
    "    input_ = Input(shape=input_shape)\n",
    "    encode = encoder(input_shape, hidden_layer_length, dropout)\n",
    "    if verbose:\n",
    "        encode.summary()\n",
    "    decode = decoder(hidden_layer_length, output_shape, dropout)\n",
    "    if verbose:\n",
    "        decode.summary()\n",
    "    model = Model(input_, decode(encode(input_)))\n",
    "    return encode, decode, model\n",
    "\n",
    "dropout = 0.2\n",
    "encoder, decoder, model = autoencoder(input_shape, output_shape, hidden_layer_length, dropout, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "original_dim = 150\n",
    "latent_dim = 150\n",
    "intermediate_dim = 150\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args, latent_dim, epsilon_std):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_50 (InputLayer)           (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_h (Dense)               (None, 150)          22650       input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 150)          22650       encoder_h[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 150)          22650       encoder_h[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 150)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 67,950\n",
      "Trainable params: 67,950\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "decoder_h (Dense)            (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "decoder_mean (Dense)         (None, 150)               22650     \n",
      "=================================================================\n",
      "Total params: 45,300\n",
      "Trainable params: 45,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "model_55 (Model)             (None, 150)               67950     \n",
      "_________________________________________________________________\n",
      "model_56 (Model)             (None, 150)               45300     \n",
      "=================================================================\n",
      "Total params: 113,250\n",
      "Trainable params: 113,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape=(150,))\n",
    "# x = Input(shape=(input_shape[0],))\n",
    "# encoder_input = Input(shape=input_shape)\n",
    "y = encoder_input\n",
    "\n",
    "# x = Reshape((input_shape[0],))(x)\n",
    "h = Dense(intermediate_dim, activation='relu', name='encoder_h')(y)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(h) # , activation='relu'\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(h) # , activation='relu'\n",
    "\n",
    "sampling_ = lambda args: sampling(args, latent_dim, epsilon_std)\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling_, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "def encoder(latent_dim, intermediate_dim = 150):\n",
    "    encoder_input = Input(shape=(150,), name='encoder_input')\n",
    "    y = encoder_input\n",
    "    h = Dense(intermediate_dim, activation='relu', name='encoder_h')(y)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(h) # , activation='relu'\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(h) # , activation='relu'\n",
    "\n",
    "    sampling_ = lambda args: sampling(args, latent_dim, epsilon_std)\n",
    "    z = Lambda(sampling_, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    encoder_model = Model(encoder_input, z)\n",
    "    encoder_model_partial = Model(encoder_input, z_mean) # z_log_var ?\n",
    "    return encoder_model, encoder_model_partial, z_mean, z_log_var\n",
    "\n",
    "def decoder(latent_dim, intermediate_dim = 150):\n",
    "    z = Input(shape=(latent_dim,), name='decoder_input')\n",
    "    decoder_h = Dense(intermediate_dim, activation='relu', name='decoder_h')\n",
    "    h_decoded = decoder_h(z)\n",
    "    decoder_mean = Dense(original_dim, activation='sigmoid', name='decoder_mean')\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "    decoder_output = x_decoded_mean\n",
    "    # x_decoded_mean = Reshape(input_shape)(x_decoded_mean)\n",
    "    model = Model(inputs=z, outputs=decoder_output)\n",
    "    return model\n",
    "\n",
    "# encoder_model, encoder_model_partial, z_mean, z_log_var = encoder(latent_dim)\n",
    "encoder_model = Model(encoder_input, z)\n",
    "\n",
    "decoder_model = decoder(latent_dim)\n",
    "# # we instantiate these layers separately so as to reuse them later\n",
    "# decoder_h = Dense(intermediate_dim, activation='relu', name='decoder_h')\n",
    "# h_decoded = decoder_h(z)\n",
    "# decoder_mean = Dense(original_dim, activation='sigmoid', name='decoder_mean')\n",
    "# x_decoded_mean = decoder_mean(h_decoded)\n",
    "# decoder_output = x_decoded_mean\n",
    "# # x_decoded_mean = Reshape(input_shape)(x_decoded_mean)\n",
    "\n",
    "vae_input = Input(shape=(150,))\n",
    "vae_output = decoder_model(encoder_model(vae_input))\n",
    "vae = Model(vae_input, vae_output)\n",
    "# vae = Model(encoder_input, decoder_model(z))\n",
    "# vae = Model(encoder_input, decoder_output)\n",
    "encoder_model.summary()\n",
    "# encoder_model_partial.summary()\n",
    "decoder_model.summary()\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Output \"model_56\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"model_56\" during training.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Compute VAE loss\n",
    "xent_loss = original_dim * metrics.binary_crossentropy(vae_input, vae_output)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z_train = x_train\n",
    "# x_train = x_train.reshape(x_train.shape[0],np.prod(x_train.shape[1:]))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_train[-10:]\n",
    "x_train = x_train[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 10 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'input_50' with dtype float and shape [?,150]\n\t [[Node: input_50 = Placeholder[dtype=DT_FLOAT, shape=[?,150], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'input_50', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-113-8222aa94d190>\", line 1, in <module>\n    encoder_input = Input(shape=(150,))\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 1457, in Input\n    input_tensor=tensor)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 1366, in __init__\n    name=self.name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 507, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3141, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_50' with dtype float and shape [?,150]\n\t [[Node: input_50 = Placeholder[dtype=DT_FLOAT, shape=[?,150], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_50' with dtype float and shape [?,150]\n\t [[Node: input_50 = Placeholder[dtype=DT_FLOAT, shape=[?,150], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-903904abd050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_50' with dtype float and shape [?,150]\n\t [[Node: input_50 = Placeholder[dtype=DT_FLOAT, shape=[?,150], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'input_50', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-113-8222aa94d190>\", line 1, in <module>\n    encoder_input = Input(shape=(150,))\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 1457, in Input\n    input_tensor=tensor)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\", line 1366, in __init__\n    name=self.name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 507, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3141, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_50' with dtype float and shape [?,150]\n\t [[Node: input_50 = Placeholder[dtype=DT_FLOAT, shape=[?,150], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "history = vae.fit(x_train, shuffle=False, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_model(vae, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(encoder_input, z_mean) # z_log_var ???\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "decoder_h (Dense)            (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "decoder_mean (Dense)         (None, 150)               22650     \n",
      "=================================================================\n",
      "Total params: 45,300\n",
      "Trainable params: 45,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "# (decoder_input == z)\n",
    "# TODO duplicate code: put this in function (just the input differs)\n",
    "generator = decoder_model # decoder_model(z)\n",
    "generator.summary()\n",
    "# decoder_input = Input(shape=(latent_dim,))\n",
    "# _h_decoded = decoder_h(decoder_input)\n",
    "# _x_decoded_mean = decoder_mean(_h_decoded)\n",
    "# generator = Model(decoder_input, _x_decoded_mean)\n",
    "# generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train[0,:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 30\n",
    "i = 0\n",
    "plt.subplot(211)\n",
    "plt.plot(np.arange(n1), results[i][:n1])\n",
    "plt.plot([0.5] * n1) # midi.MIDI_NOISE_FLOOR\n",
    "plt.ylim(ymin=0, ymax=1)\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.plot(np.arange(n1), x_train[i, :n1])\n",
    "plt.plot([0.5] * n1) # midi.MIDI_NOISE_FLOOR\n",
    "plt.ylim(ymin=0, ymax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = midi.decode_track(context, result)\n",
    "dn = config.dataset_dir\n",
    "# io.export_midifile(mid, dn + 'song_seq-seq.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "latent_samples = []\n",
    "for seq in x_test[-2:]:\n",
    "    encoded = encode_sequence(np.stack([seq]))\n",
    "    latent_samples.append(encoded)\n",
    "    result = decode_sequence(encoded, encoder_model, decoder_model)\n",
    "    results.append(result)\n",
    "results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(encoded[0][0,:10])\n",
    "plt.plot(encoded[1][0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array(latent_samples)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensionality\n",
    "# e = e.reshape(e.shape[0],2,e.shape[-1])\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = e.transpose().mean(axis=1).transpose()\n",
    "e1 = e[:,0] # state h\n",
    "e2 = e[:,1] # state c\n",
    "new = [e1.mean(axis=0), e2.mean(axis=0)]\n",
    "# new = [[e[:,i].mean(axis=0)] for i in [0,1]]\n",
    "plt.plot(new[0][0][:10])\n",
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = latent_samples[0]\n",
    "len(l) # latent_sample :: (x,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ = decode_sequence(latent_samples[0], encoder_model, decoder_model)\n",
    "new_ = decode_sequence(new, encoder_model, decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_new = midi.decode_track(context, results[0])\n",
    "io.export_midifile(mid_new, config.export_dir + 'real_mid_new_lstm.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test, y_test = gen_xy_sin_to_f(3, f=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.predict([x_test,x_test])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'true' results\n",
    "i = 0\n",
    "selection = int(x_test.shape[1] * 1)\n",
    "full = np.concatenate([x_test[i,-selection:],y_test[i]])\n",
    "n3 = full.shape[0]\n",
    "plt.plot(np.arange(n3) / n3 * dt, full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted results\n",
    "i = 0\n",
    "full = np.concatenate([x_test[i,-selection:],results[i]])\n",
    "n3 = full.shape[0]\n",
    "plt.plot(np.arange(n3) / n3 * dt, full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "selection = int(x_test.shape[1] * 1)\n",
    "full = np.concatenate([x_test[i,-selection:],results[i]])\n",
    "n3 = full.shape[0]\n",
    "plt.plot(np.arange(n3) / n3 * dt, full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "selection = 1\n",
    "full = np.concatenate([x_test[i,-selection:],results[i]])\n",
    "n3 = full.shape[0]\n",
    "plt.plot(np.arange(n3) / n3 * dt, full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
