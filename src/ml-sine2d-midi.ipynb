{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os, numpy as np, pandas, sklearn, scipy.signal as signal\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## NN libs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Input, Dense, Activation, Conv1D, Conv2D, Dropout, Flatten\n",
    "from keras.layers import Conv2DTranspose, Reshape, MaxPooling2D, UpSampling2D, UpSampling1D, MaxPooling1D\n",
    "from keras.layers import LocallyConnected1D, LocallyConnected2D\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# local libs\n",
    "import config, models, functions\n",
    "from data import data, midi, midi_generators as g\n",
    "from utils import io, models_io, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.1\n",
      " >> Context(max_t=10.0, dt=0.02, n_instances=500, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n"
     ]
    }
   ],
   "source": [
    "context = data.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a generator\n",
    "\n",
    "1. What is the least amount of 'hidden' nodes needed to learn a straight rythm (e.g. 8th notes with different frequencies)\n",
    "2. Can we create a model of a generic function sin(2 pi f t + phase)\n",
    "    - using x: t -> y: sin(2p t)\n",
    "    - using x: [f, t, phase] -> y: sin(2p f t + phase)\n",
    "    - using x: sin([t1, t2, t3) -> y: [f, t, phase]\n",
    "        - such a model should be able to learn complex patterns, such as sin(f1+p1) + sin(f2+p2) + sin(f3+p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.007291666666665\n",
      " |>  500\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  9.997916666666667\n",
      " |>  500\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  10.002083333333331\n",
      " |>  500\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  WARNING\n",
      " |>  type not == 0\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "fs = np.repeat(1, n)\n",
    "fs = None\n",
    "x_train = g.gen_data(context, n, fs=fs)\n",
    "# x_train = np.zeros([10,100,127])\n",
    "y_train = x_train[:,-1]\n",
    "x_train = x_train[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 499, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b389c50>,\n",
       " <matplotlib.lines.Line2D at 0x11b389da0>,\n",
       " <matplotlib.lines.Line2D at 0x11b389ef0>,\n",
       " <matplotlib.lines.Line2D at 0x11b396080>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b279358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train[0,:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = x_train[0]\n",
    "input_shape = x_train.shape[1:] # shape of a single sample\n",
    "output_shape = y_train[0].shape # shape of a single sample\n",
    "# output_length = y_train.shape[1:][0]\n",
    "hidden_layer_length = 10\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 128)         68096     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 200,196\n",
      "Trainable params: 200,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model(input_shape, output_shape):\n",
    "    n_categories = input_shape[-1]\n",
    "#     input_layer = Input(shape=input_shape)\n",
    "    # input shape = (None, None, 1)\n",
    "    # thus: unfixed n samples, unfixed n timesteps, 1 float value\n",
    "    input_layer = Input(shape=(None, n_categories))\n",
    "    x = input_layer\n",
    "    \n",
    "    hidden_size = 128\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(hidden_size, return_state=False, return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    w = np.prod(output_shape)\n",
    "    print('w =',w)\n",
    "    w = 100\n",
    "#     x = Dense(w, activation='relu')(x)\n",
    "\n",
    "    x = Dense(np.prod(output_shape), activation='sigmoid')(x)\n",
    "    x = Reshape(output_shape)(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = model(input_shape, output_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy','mse','binary_crossentropy'] # sparse_categorical_accuracy\n",
    "loss = 'sparse_categorical_crossentropy'# binary_crossentropy categorical_crossentropy sparse_categorical_crossentropy\n",
    "optimizer = 'adadelta'\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['mse', 'mae'])#, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected reshape_2 to have shape (1,) but got array with shape (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7602bb7d281a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# decoder.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[TensorBoard(log_dir=config.tmp_log_dir)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n\u001b[0;32m----> 3\u001b[0;31m           validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_log_dir)])\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected reshape_2 to have shape (1,) but got array with shape (4,)"
     ]
    }
   ],
   "source": [
    "# decoder.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[TensorBoard(log_dir=config.tmp_log_dir)])\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_log_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# full = np.concatenate([x_test[i,-selection:],results[i]])\n",
    "# n3 = full.shape[0]\n",
    "plt.plot(x_train[0,:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = x_train[0,:250]\n",
    "for _ in range(250):\n",
    "    results = model.predict(np.stack([x[:]]))\n",
    "    last_value = results[0]\n",
    "    x = np.concatenate([x, [last_value]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "selection = int(x_test.shape[1] * 1)\n",
    "full = np.concatenate([x_test[i,-selection:],results[i]])\n",
    "n3 = full.shape[0]\n",
    "plt.plot(np.arange(n3) / n3 * dt, full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_point_by_point(encoder, x_train)\n",
    "plt.plot(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
