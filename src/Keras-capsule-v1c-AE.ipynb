{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# local libs\n",
    "import config, models, functions\n",
    "from data import data, midi, midi_generators as g\n",
    "from utils import io, models_io, utils, plot\n",
    "from capsule.layers import Capsule, Length\n",
    "from capsule.capsulefunctions import squash, softmax, margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.02, n_instances=100, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.02, n_instances=100, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Importing midi-data\n",
      "\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/01 16th Snare.mid\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/01 8th Cym.mid\n",
      "\n",
      "Encoding midi-data\n",
      " [<midi file '../datasets/examples/01 16th Snare.mid' type 0, 1 tracks, 182 messages>, <midi file '../datasets/examples/01 8th Cym.mid' type 0, 1 tracks, 68 messages>]\n",
      "> -> multi-track = True\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9947916666666667\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9947916666666667\n",
      " |>  100\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reduced dims:\n",
      " |  (2, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "context = data.init()\n",
    "n = 2\n",
    "multiTrack = True\n",
    "context, x_train, labels = data.import_data(data.init(), n, multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.993749999999999\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0291666666666663\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.013541666666666\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9916666666666667\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9979166666666666\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0249999999999986\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.025\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.003125\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9947916666666667\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9958333333333325\n",
      " |>  100\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reduced dims:\n",
      " |  (10, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "min_f = 3\n",
    "max_f = 15\n",
    "# x_train = g.gen_data(context, n, max_f=max_f, min_f=min_f)\n",
    "# x_train = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f, multiTrack=multiTrack)\n",
    "x_train = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f, \n",
    "    n_polyrythms=1,\n",
    "    n_channels=3,\n",
    "    multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "total = 1000 * 1\n",
    "x_test = x_train[n:]\n",
    "x_train = np.concatenate([x_train[:n] for _ in range(int(total/n))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Usage of keras.image.ImageDataGenerator requires 3 dims</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(list(x_train.shape) + [1])\n",
    "x_test = x_train[:-500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train\n",
    "y_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.concatenate([list(range(n)) for _ in range(int(total/n)+1)])[:total]\n",
    "# y_train = keras.utils.to_categorical(y_train)\n",
    "# y_test = y_train[-500:]\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "m = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train = x_train[:m].astype('float32')\n",
    "# x_test = x_test[:1000].astype('float32')\n",
    "# y_train = y_train[:m]\n",
    "# y_test = y_train[:1000]\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 3, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (30, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117081160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(x_train[0,:,:,0])\n",
    "plot.multi(x_train[0,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights, shape = (1, 128, 160) 20480\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, None, 64)          12352     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, None, 128)         24704     \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "reshape_16 (Reshape)         (None, None, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "capsule_3 (Capsule)          (None, 10, 16)            20480     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 160)               0         \n",
      "=================================================================\n",
      "Total params: 107,072\n",
      "Trainable params: 107,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps, notes, channels = input_shape\n",
    "\n",
    "encoder_input = Input(shape=(None, None, channels))\n",
    "x = encoder_input\n",
    "\n",
    "# 1D\n",
    "x = Reshape((-1, 1))(x)\n",
    "x = Conv1D(64, 3, activation='relu', padding='valid')(x)\n",
    "x = Conv1D(64, 3, activation='relu', padding='valid')(x)\n",
    "x = AveragePooling1D(2)(x)\n",
    "x = Conv1D(128, 3, activation='relu', padding='valid')(x)\n",
    "x = Conv1D(128, 3, activation='relu', padding='valid')(x)\n",
    "x = Reshape((-1, 1, 1))(x)\n",
    "\n",
    "x = Reshape((-1, 128))(x)\n",
    "n_capsules = 10\n",
    "capsule_dim = 16\n",
    "n_routings=3\n",
    "share_weights=True\n",
    "capsule = Capsule(n_capsules, capsule_dim, n_routings, share_weights)(x)\n",
    "x = capsule\n",
    "\n",
    "# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "# If using tensorflow, this will not be necessary.\n",
    "# x = Length(name='capsnet')(capsule)\n",
    "# x = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "# x = Lambda(lambda z: K.sqrt(K.sum(K.square(z), -1)))(capsule)\n",
    "\n",
    "x = Flatten()(capsule)\n",
    "# x = Dense(np.prod(input_shape), activation='sigmoid')(x)\n",
    "# x = Reshape(input_shape)(x)\n",
    "\n",
    "\n",
    "encoder_output = x\n",
    "\n",
    "encoder_model = Model(encoder_input, encoder_output, name='encoder-')\n",
    "encoder_model.summary() # output.shape = (None, 10)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.compile(loss='mse', optimizer='adam')\n",
    "# x = encoder_model.predict(x_train[:10])\n",
    "# x.shape # == (10, 100, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.fit(x_train[:10], x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.compile(loss='mse', optimizer='adam')\n",
    "# x = encoder_model.predict(x_train[:10])\n",
    "# x.shape # == (10, 100, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_decoders(input_shape, output_shape, intermediate_dim=150, p='valid'):\n",
    "    # cols, rows, color-channels (rgb)\n",
    "    timesteps, notes, channels = output_shape\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "    decoders = []\n",
    "    if len(input_shape) > 1:\n",
    "        decoders += [ Flatten() ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "\n",
    "    # output_shape = (timesteps, notes, channels)\n",
    "    decoders += [ Dense(np.prod(output_shape), activation='sigmoid')]\n",
    "    decoders += [ Reshape(output_shape)]\n",
    "    return decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x11af15128>\n",
      "<keras.layers.core.Dense object at 0x11af152b0>\n",
      "<keras.layers.core.Dense object at 0x11af15668>\n",
      "<keras.layers.core.Reshape object at 0x11af156d8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               82432     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 300)               153900    \n",
      "_________________________________________________________________\n",
      "reshape_28 (Reshape)         (None, 100, 3, 1)         0         \n",
      "=================================================================\n",
      "Total params: 498,988\n",
      "Trainable params: 498,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_output_shape = (n_capsules, capsule_dim) # (n_capsules, capsule_dim,)\n",
    "# encoder_output_shape = (n_capsules,) # (n_capsules, capsule_dim,)\n",
    "encoder_output_shape = (160,)\n",
    "decoder_input_shape = encoder_output_shape\n",
    "decoder_input = Input(shape=decoder_input_shape)\n",
    "# decoder_input = encoder_model(encoder_input)\n",
    "# decoder_input = encoder_output\n",
    "\n",
    "decoder_pipeline = list_decoders(decoder_input_shape, output_shape=input_shape)\n",
    "decoded = utils.composition(decoder_pipeline, decoder_input, verbose=True)\n",
    "\n",
    "decoder_model = Model(decoder_input, decoded, name='decoder-')\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "encoder- (Model)             (None, 160)               107072    \n",
      "_________________________________________________________________\n",
      "decoder- (Model)             (None, 100, 3, 1)         498988    \n",
      "=================================================================\n",
      "Total params: 606,060\n",
      "Trainable params: 606,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_input = encoder_input\n",
    "# ae_output = decoded\n",
    "ae_output = decoder_model(encoder_model(encoder_input))\n",
    "# ae = Model(encoder_input, decoder_model(encoder_model(encoder_input)))\n",
    "# ae_output = decoded.\n",
    "# ae_encoder_output = encoder_model(encoder_input)\n",
    "# ae_decoder_output = decoder_model(ae_encoder_output)\n",
    "# ae_output = [ae_encoder_output, ae_decoder_output]\n",
    "\n",
    "ae = Model(ae_input, ae_output, name='AE')\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(alpha=1., beta=1.):\n",
    "#     encoder_loss = margin_loss(encoder_input, encoder_output)\n",
    "#     xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(ae_input), K.flatten(ae_output))\n",
    "#     # xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(y1), K.flatten(y2))\n",
    "#     # return = K.mean(alpha * encoder_loss + beta * xent_loss)\n",
    "#     loss = K.mean(encoder_loss + xent_loss)\n",
    "#     return xent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_ = loss()\n",
    "# ae.add_loss(loss_)\n",
    "# ae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae = encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = [margin_loss, 'binary_crossentropy']\n",
    "loss = 'binary_crossentropy' # mse mae binary_crossentropy\n",
    "ae.compile(loss=loss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_ = lambda y_true, y_pred = loss(ae_input, ae_output)\n",
    "# loss_ = loss\n",
    "# loss_ = 'binary_crossentropy'\n",
    "\n",
    "# ae.compile(loss=loss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mod = 0.1\n",
    "whitening = False\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by dataset std\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_epsilon=10,\n",
    "        zca_whitening=whitening,\n",
    "        rotation_range=0,  # randomly rotate images in 0 to 180 degrees\n",
    "        width_shift_range=0.,  # note-channel mod, but not shuffled\n",
    "        height_shift_range=phase_mod,  # start_t, phase\n",
    "        horizontal_flip=False,  # reverse\n",
    "        vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 3, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/15\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.6399 - acc: 0.3266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-922cd65dc3fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         workers=4)\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_augmentation = False\n",
    "data_augmentation = True\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "#     history = ae.fit(x_train, epochs=epochs, validation_data=(x_test, None))\n",
    "    history = ae.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')    \n",
    "    history = ae.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = datagen.random_transform(x_train[i])\n",
    "plot.multi(x[:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = datagen.standardize(x_train[i:i+batch_size])\n",
    "x.shape\n",
    "x = x[0]\n",
    "plot.multi(x[:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_train[i,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = ae.predict(x_train[:10])\n",
    "plot.multi(x[i,:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x[i,:,:,0]\n",
    "threshold = midi.MIDI_NOISE_FLOOR\n",
    "idx = x2[:,:] > threshold\n",
    "x2[idx] = 1\n",
    "plot.multi(x2[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
