{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas, sklearn\n",
    "import mido, rtmidi, rtmidi_\n",
    "np.random.seed(333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " '__init__.py',\n",
       " '__pycache__',\n",
       " 'config.py',\n",
       " 'data',\n",
       " 'errors.py',\n",
       " 'main.py',\n",
       " 'ml-autoencoder.ipynb',\n",
       " 'ml-v1.ipynb',\n",
       " 'models.py',\n",
       " 'rtmidi_',\n",
       " 'sparql.py',\n",
       " 'test_midi.py',\n",
       " 'utils']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## NN libs\n",
    "from sklearn.decomposition import PCA\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Input, Dense, Activation, Conv1D, Conv2D, Dropout, Flatten\n",
    "from keras.layers import Conv2DTranspose, Reshape, MaxPooling2D, UpSampling2D, UpSampling1D, MaxPooling1D\n",
    "from keras.layers import LocallyConnected1D, LocallyConnected2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# local libs\n",
    "import config\n",
    "from data import data, midi\n",
    "from utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      " >> Context(max_t=10.0, dt=0.01, n_instances=1000, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Importing midi-data\n",
      "\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/01 16th Snare copy.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/01 16th Snare.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/01 8th Cym copy.mid\n",
      "[INFO] :\n",
      " |  reading file: ../datasets/examples/01 8th Cym.mid\n",
      "\n",
      "Encoding midi-data\n",
      " [<midi file '../datasets/examples/01 16th Snare copy.mid' type 0, 1 tracks, 182 messages>, <midi file '../datasets/examples/01 16th Snare.mid' type 0, 1 tracks, 182 messages>, <midi file '../datasets/examples/01 8th Cym copy.mid' type 0, 1 tracks, 68 messages>, <midi file '../datasets/examples/01 8th Cym.mid' type 0, 1 tracks, 68 messages>]\n",
      "(4, 1000, 127)\n"
     ]
    }
   ],
   "source": [
    "n: int = 4\n",
    "context, x_train = data.init(n)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "Input -> hidden layer -> output (=input)\n",
    "Hidden layer has few dimension. Latent space of this layer should produce automatic categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1000, 127)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = x_train\n",
    "n_samples = x_train[0]\n",
    "input_shape = x_train.shape[1:] # shape of a single sample\n",
    "output_shape = y_train.shape[1:]\n",
    "# output_length = y_train.shape[1]\n",
    "# output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1000, 127)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 127)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        (None, 1000, 127)         0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 127000)            0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               12700100  \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1000)              101000    \n",
      "_________________________________________________________________\n",
      "reshape_32 (Reshape)         (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_33 (UpSampling (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 50, 100)           20100     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_34 (UpSampling (None, 1000, 100)         0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1000, 127)         12827     \n",
      "=================================================================\n",
      "Total params: 12,834,027\n",
      "Trainable params: 12,834,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def encoder(input_shape, output_shape, dropout=0.10):\n",
    "    t = 1000\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    shape = (10,100) # 1 additional dimension\n",
    "    x = Dense(np.prod(shape), activation='relu')(x) # 4*4*8 = 128\n",
    "    x = Reshape(shape)(x)\n",
    "    x = UpSampling1D(10)(x)\n",
    "    x = Conv1D(100, 2, strides=2, activation='relu')(x) # 50,100\n",
    "    x = UpSampling1D(output_shape[0] / 50)(x)\n",
    "    x = Dense(output_shape[1], activation='relu')(x) # \n",
    "    # x = Dense(output_length, activation='softmax')(x)\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    #     model.add(Dropout(dropout))\n",
    "    return model, model.summary\n",
    "\n",
    "dropout = 0.\n",
    "model, summary = encoder(input_shape, output_shape, dropout)\n",
    "summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# sgd = Keras.optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "# top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "# https://keras.io/metrics/\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy','mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 1 samples\n",
      "Epoch 1/9\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 2.5627 - acc: 0.1773 - mean_squared_error: 344081.7969 - val_loss: 18.1346 - val_acc: 0.2000 - val_mean_squared_error: 527711.2500\n",
      "Epoch 2/9\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 2.5615 - acc: 0.1390 - mean_squared_error: 351183.1514 - val_loss: 18.1726 - val_acc: 0.1000 - val_mean_squared_error: 534039.8750\n",
      "Epoch 3/9\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 2.5612 - acc: 0.0390 - mean_squared_error: 355507.1465 - val_loss: 18.2189 - val_acc: 0.0000e+00 - val_mean_squared_error: 539033.7500\n",
      "Epoch 4/9\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 2.5602 - acc: 0.2057 - mean_squared_error: 359108.9001 - val_loss: 18.2169 - val_acc: 0.3000 - val_mean_squared_error: 543176.1875\n",
      "Epoch 5/9\n",
      "3/3 [==============================] - 1s 255ms/step - loss: 2.5600 - acc: 0.2390 - mean_squared_error: 361118.1725 - val_loss: 18.1878 - val_acc: 0.2000 - val_mean_squared_error: 545598.8750\n",
      "Epoch 6/9\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 2.5594 - acc: 0.1057 - mean_squared_error: 362569.7148 - val_loss: 18.1806 - val_acc: 0.1000 - val_mean_squared_error: 548279.2500\n",
      "Epoch 7/9\n",
      "3/3 [==============================] - 1s 268ms/step - loss: 2.5597 - acc: 0.0843 - mean_squared_error: 363469.1497 - val_loss: 18.1686 - val_acc: 0.4000 - val_mean_squared_error: 548663.0000\n",
      "Epoch 8/9\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 2.5596 - acc: 0.3510 - mean_squared_error: 363978.2542 - val_loss: 18.1696 - val_acc: 0.5000 - val_mean_squared_error: 549052.3750\n",
      "Epoch 9/9\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 2.5595 - acc: 0.2447 - mean_squared_error: 364111.1553 - val_loss: 18.1748 - val_acc: 0.2000 - val_mean_squared_error: 549555.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ede2470>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
