{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# local libs\n",
    "import config, models, functions\n",
    "from data import data, midi, midi_generators as g\n",
    "from utils import io, models_io, utils, plot\n",
    "from capsule.layers import Capsule, Length\n",
    "from capsule.capsulefunctions import squash, softmax, margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.02, n_instances=100, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.02, n_instances=100, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Importing midi-data\n",
      "\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/01 16th Snare.mid\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/01 8th Cym.mid\n",
      "\n",
      "Encoding midi-data\n",
      " [<midi file '../datasets/examples/01 16th Snare.mid' type 0, 1 tracks, 182 messages>, <midi file '../datasets/examples/01 8th Cym.mid' type 0, 1 tracks, 68 messages>]\n",
      "> -> multi-track = True\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9947916666666667\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9947916666666667\n",
      " |>  100\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reduced dims:\n",
      " |  (2, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "context = data.init()\n",
    "n = 2\n",
    "multiTrack = True\n",
    "context, x_train, labels = data.import_data(data.init(), n, multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9927083333333333\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9927083333333326\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9916666666666663\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0072916666666667\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9916666666666671\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.009375\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.991666666666667\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9958333333333338\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.009375\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.000000000000001\n",
      " |>  100\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reduced dims:\n",
      " |  (10, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "min_f = 3\n",
    "max_f = 15\n",
    "# x_train = g.gen_data(context, n, max_f=max_f, min_f=min_f)\n",
    "# x_train = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f, multiTrack=multiTrack)\n",
    "x_train = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f, \n",
    "    n_polyrythms=1,\n",
    "    n_channels=3,\n",
    "    multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "total = 1000 * 1\n",
    "x_test = x_train[n:]\n",
    "x_train = np.concatenate([x_train[:n] for _ in range(int(total/n))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Usage of keras.image.ImageDataGenerator requires 3 dims</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(list(x_train.shape) + [1])\n",
    "x_test = x_train[:-500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train\n",
    "y_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train = np.concatenate([list(range(n)) for _ in range(int(total/n)+1)])[:total]\n",
    "# y_train = keras.utils.to_categorical(y_train)\n",
    "# y_test = y_train[-500:]\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "m = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train = x_train[:m].astype('float32')\n",
    "# x_test = x_test[:1000].astype('float32')\n",
    "# y_train = y_train[:m]\n",
    "# y_test = y_train[:1000]\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 3, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (30, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11768b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(x_train[0,:,:,0])\n",
    "plot.multi(x_train[0,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights, shape = (1, 128, 160) 20480\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "reshape_33 (Reshape)         (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, None, 64)          12352     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, None, 128)         24704     \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "reshape_34 (Reshape)         (None, None, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "reshape_35 (Reshape)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "capsule_5 (Capsule)          (None, 10, 16)            20480     \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 300)               3300      \n",
      "_________________________________________________________________\n",
      "reshape_36 (Reshape)         (None, 100, 3, 1)         0         \n",
      "=================================================================\n",
      "Total params: 110,372\n",
      "Trainable params: 110,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps, notes, channels = input_shape\n",
    "\n",
    "encoder_input = Input(shape=(None, None, channels))\n",
    "x = encoder_input\n",
    "\n",
    "# 1D\n",
    "x = Reshape((-1, 1))(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = AveragePooling1D(2)(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = Reshape((-1, 1,1))(x)\n",
    "\n",
    "# 2D\n",
    "# x = Reshape(x_train.shape[:-1])(x)\n",
    "# x = Conv2D(64, (3,3), activation='relu')(input_image)\n",
    "# x = Conv2D(64, kernel_size, activation='relu')(x)\n",
    "# x = AveragePooling2D((2, 2))(x)\n",
    "# x = Conv2D(128, kernel_size, activation='relu')(x)\n",
    "# x = Conv2D(128, kernel_size, activation='relu')(x)\n",
    "\n",
    "\"\"\"now we reshape it as (batch_size, input_num_capsule, input_dim_capsule)\n",
    "then connect a Capsule layer.\n",
    "\n",
    "the output of final model is the lengths of 10 Capsule, whose dim=16.\n",
    "\n",
    "the length of Capsule is the proba,\n",
    "so the problem becomes a 10 two-classification problem.\n",
    "\"\"\"\n",
    "\n",
    "x = Reshape((-1, 128))(x)\n",
    "n_capsules = 10\n",
    "capsule_dim = 16\n",
    "n_routings=3\n",
    "share_weights=True\n",
    "capsule = Capsule(n_capsules, capsule_dim, n_routings, share_weights)(x)\n",
    "\n",
    "# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "# If using tensorflow, this will not be necessary.\n",
    "# x = Length(name='capsnet')(capsule)\n",
    "x = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "\n",
    "x = Dense(np.prod(input_shape), activation='sigmoid')(x)\n",
    "x = Reshape(input_shape)(x)\n",
    "\n",
    "encoder_output = x\n",
    "\n",
    "encoder_model = Model(encoder_input, encoder_output, name='encoder-')\n",
    "encoder_model.summary() # output.shape = (None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 3, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.compile(loss='mse', optimizer='adam')\n",
    "x = encoder_model.predict(x_train[:10])\n",
    "x.shape # == (10, 100, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.6922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a692ac8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.fit(x_train[:10], x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.compile(loss='mse', optimizer='adam')\n",
    "# x = encoder_model.predict(x_train[:10])\n",
    "# x.shape # == (10, 100, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_decoders(input_shape, output_shape, intermediate_dim=150, p='valid'):\n",
    "    # cols, rows, color-channels (rgb)\n",
    "    timesteps, notes, channels = output_shape\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "    decoders = []\n",
    "    if len(input_shape) > 1:\n",
    "        decoders += [ Flatten() ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "\n",
    "    # output_shape = (timesteps, notes, channels)\n",
    "    decoders += [ Dense(np.prod(output_shape), activation='sigmoid')]\n",
    "    decoders += [ Reshape(output_shape)]\n",
    "    return decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_shape = (n_capsules, capsule_dim) # (n_capsules, capsule_dim,)\n",
    "encoder_output_shape = (n_capsules,) # (n_capsules, capsule_dim,)\n",
    "decoder_input_shape = encoder_output_shape\n",
    "# decoder_input = Input(shape=decoder_input_shape)\n",
    "# decoder_input = encoder_model(encoder_input)\n",
    "decoder_input = encoder_output\n",
    "\n",
    "\n",
    "decoder_pipeline = list_decoders(decoder_input_shape, output_shape=input_shape)\n",
    "decoded = utils.composition(decoder_pipeline, decoder_input, verbose=False)\n",
    "\n",
    "# decoder_model = Model(decoder_input, decoded, name='decoder-')\n",
    "# decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, None, 64)          12352     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, None, 128)         24704     \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "reshape_14 (Reshape)         (None, None, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "capsule_3 (Capsule)          (None, 10, 16)            20480     \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               5632      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 300)               153900    \n",
      "_________________________________________________________________\n",
      "reshape_28 (Reshape)         (None, 100, 3, 1)         0         \n",
      "=================================================================\n",
      "Total params: 529,260\n",
      "Trainable params: 529,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_input = encoder_input\n",
    "ae_output = decoded\n",
    "# ae_output = decoder_model(encoder_model(encoder_input))\n",
    "# ae = Model(encoder_input, decoder_model(encoder_model(encoder_input)))\n",
    "# ae_output = decoded.\n",
    "# ae_encoder_output = encoder_model(encoder_input)\n",
    "# ae_decoder_output = decoder_model(ae_encoder_output)\n",
    "# ae_output = [ae_encoder_output, ae_decoder_output]\n",
    "\n",
    "ae = Model(ae_input, ae_output, name='AE')\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(alpha=1., beta=1.):\n",
    "#     encoder_loss = margin_loss(encoder_input, encoder_output)\n",
    "#     xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(ae_input), K.flatten(ae_output))\n",
    "#     # xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(y1), K.flatten(y2))\n",
    "#     # return = K.mean(alpha * encoder_loss + beta * xent_loss)\n",
    "#     loss = K.mean(encoder_loss + xent_loss)\n",
    "#     return xent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_ = loss()\n",
    "# ae.add_loss(loss_)\n",
    "# ae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = [margin_loss, 'binary_crossentropy']\n",
    "loss = 'binary_crossentropy' # mse mae binary_crossentropy\n",
    "ae.compile(loss=loss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_ = lambda y_true, y_pred = loss(ae_input, ae_output)\n",
    "# loss_ = loss\n",
    "# loss_ = 'binary_crossentropy'\n",
    "\n",
    "# ae.compile(loss=loss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mod = 0.1\n",
    "whitening = False\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by dataset std\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_epsilon=10,\n",
    "        zca_whitening=whitening,\n",
    "        rotation_range=0,  # randomly rotate images in 0 to 180 degrees\n",
    "        width_shift_range=0.,  # note-channel mod, but not shuffled\n",
    "        height_shift_range=phase_mod,  # start_t, phase\n",
    "        horizontal_flip=False,  # reverse\n",
    "        vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected reshape_36 to have 4 dimensions, but got array with shape (1000, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-96939f39543c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         shuffle=True)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using real-time data augmentation.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected reshape_36 to have 4 dimensions, but got array with shape (1000, 10)"
     ]
    }
   ],
   "source": [
    "data_augmentation = False\n",
    "# data_augmentation = True\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "#     history = ae.fit(x_train, epochs=epochs, validation_data=(x_test, None))\n",
    "    history = ae.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')    \n",
    "    history = ae.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = datagen.random_transform(x_train[i])\n",
    "plot.multi(x[:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = datagen.standardize(x_train[i:i+batch_size])\n",
    "x.shape\n",
    "x = x[0]\n",
    "plot.multi(x[:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_train[i,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = ae.predict(x_train[:10])\n",
    "plot.multi(x[i,:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x[i,:,:,0]\n",
    "threshold = midi.MIDI_NOISE_FLOOR\n",
    "idx = x2[:,:] > threshold\n",
    "x2[idx] = 1\n",
    "plot.multi(x2[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
