{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Context :: namedtuple(\n",
      "[ max_t = float\n",
      ", dt = float\n",
      ", n_instances = int\n",
      ", note_length = int\n",
      ", bpm = float\n",
      ", tempo = float\n",
      ", ticks_per_beat = int\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# local libs\n",
    "import config, models, functions\n",
    "from data import data, midi, midi_generators as g\n",
    "from utils import io, models_io, utils, plot\n",
    "from capsule.layers import Capsule, Length\n",
    "from capsule.capsulefunctions import squash, softmax, margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.02, n_instances=100, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Setting up params\n",
      "\n",
      "max min f 25.0 0.5\n",
      " >> Context(max_t=2.0, dt=0.02, n_instances=100, note_length=0.03, bpm=120.0, tempo=500000, ticks_per_beat=480)\n",
      "Importing midi-data\n",
      "\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/simple-straight-120.mid\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reading file: ../datasets/examples/simple-shuffle-120.mid\n",
      "\n",
      "Encoding midi-data\n",
      " [<midi file '../datasets/examples/simple-straight-120.mid' type 0, 1 tracks, 68 messages>, <midi file '../datasets/examples/simple-shuffle-120.mid' type 0, 1 tracks, 68 messages>]\n",
      "> -> multi-track = True\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0\n",
      " |>  100\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reduced dims:\n",
      " |  (2, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "context = data.init()\n",
    "n = 2\n",
    "multiTrack = True\n",
    "context, x_train, labels = data.import_data(data.init(), n, multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9916666666666665\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9937499999999992\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0687499999999996\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0177083333333323\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9979166666666672\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9968749999999997\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0041666666666664\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  1.9927083333333329\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0020833333333337\n",
      " |>  100\n",
      "\u001b[91m [DEBUG] > \u001b[0m\n",
      " |>  to_array: msg.time > max_t; t, n\n",
      " |>  2.0020833333333323\n",
      " |>  100\n",
      "\u001b[92m [INFO] : \u001b[0m\n",
      " |  reduced dims:\n",
      " |  (10, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "min_f = 3\n",
    "max_f = 15\n",
    "# x_train = g.gen_data(context, n, max_f=max_f, min_f=min_f)\n",
    "# x_train = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f, multiTrack=multiTrack)\n",
    "x_train = g.gen_data_complex(context, n, max_f=max_f, min_f=min_f, \n",
    "    n_polyrythms=1,\n",
    "    n_channels=3,\n",
    "    multiTrack=multiTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "total = 1000 * 1\n",
    "x_test = x_train[n:]\n",
    "x_train = np.concatenate([x_train[:n] for _ in range(int(total/n))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Usage of keras.image.ImageDataGenerator requires 3 dims</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(list(x_train.shape) + [1])\n",
    "x_test = x_train[:-500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train\n",
    "y_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.concatenate([list(range(n)) for _ in range(int(total/n)+1)])[:total]\n",
    "# y_train = keras.utils.to_categorical(y_train)\n",
    "# y_test = y_train[-500:]\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "m = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train = x_train[:m].astype('float32')\n",
    "# x_test = x_test[:1000].astype('float32')\n",
    "# y_train = y_train[:m]\n",
    "# y_test = y_train[:1000]\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 3, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 3, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m (30, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f6360b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(x_train[0,:,:,0])\n",
    "plot.multi(x_train[0,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights, shape = (1, 128, 160) 20480\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "reshape_116 (Reshape)        (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, None, 64)          12352     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_36 (Averag (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, None, 128)         24704     \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "reshape_117 (Reshape)        (None, None, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "reshape_118 (Reshape)        (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "capsule_36 (Capsule)         (None, 10, 16)            20480     \n",
      "=================================================================\n",
      "Total params: 107,072\n",
      "Trainable params: 107,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps, notes, channels = input_shape\n",
    "\n",
    "encoder_input = Input(shape=(None, None, channels))\n",
    "x = encoder_input\n",
    "\n",
    "# 1D\n",
    "x = Reshape((-1, 1))(x)\n",
    "x = Conv1D(64, 3, activation='relu', padding='valid')(x)\n",
    "x = Conv1D(64, 3, activation='relu', padding='valid')(x)\n",
    "x = AveragePooling1D(2)(x)\n",
    "x = Conv1D(128, 3, activation='relu', padding='valid')(x)\n",
    "x = Conv1D(128, 3, activation='relu', padding='valid')(x)\n",
    "x = Reshape((-1, 1, 1))(x)\n",
    "\n",
    "x = Reshape((-1, 128))(x)\n",
    "n_capsules = 10\n",
    "capsule_dim = 16\n",
    "n_routings=3\n",
    "share_weights=True\n",
    "capsule = Capsule(n_capsules, capsule_dim, n_routings, share_weights)(x)\n",
    "x = capsule\n",
    "\n",
    "# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "# If using tensorflow, this will not be necessary.\n",
    "# x = Length(name='capsnet')(capsule)\n",
    "# x = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "# x = Lambda(lambda z: K.sqrt(K.sum(K.square(z), -1)))(capsule)\n",
    "\n",
    "# x = Flatten()(capsule)\n",
    "# x = Dense(np.prod(input_shape), activation='sigmoid')(x)\n",
    "# x = Reshape(input_shape)(x)\n",
    "\n",
    "\n",
    "encoder_output = x\n",
    "\n",
    "encoder_model = Model(encoder_input, encoder_output, name='encoder-')\n",
    "encoder_model.summary() # output.shape = (None, 10)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 3, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_model.compile(loss='mse', optimizer='adam')\n",
    "# x = encoder_model.predict(x_train[:10])\n",
    "# x.shape # == (10, 100, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.1325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f636240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_model.fit(x_train[:10], x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model.compile(loss='mse', optimizer='adam')\n",
    "# x = encoder_model.predict(x_train[:10])\n",
    "# x.shape # == (10, 100, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_decoders(input_shape, output_shape, intermediate_dim=150, p='valid'):\n",
    "    # cols, rows, color-channels (rgb)\n",
    "    timesteps, notes, channels = output_shape\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "    decoders = []\n",
    "    if len(input_shape) > 1:\n",
    "        decoders += [ Flatten() ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "    decoders += [ Dense(512, activation='relu') ]\n",
    "\n",
    "    # output_shape = (timesteps, notes, channels)\n",
    "    decoders += [ Dense(np.prod(output_shape), activation='sigmoid')]\n",
    "    decoders += [ Reshape(output_shape)]\n",
    "    return decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_shape = (n_capsules, capsule_dim) # (n_capsules, capsule_dim,)\n",
    "encoder_output_shape = (n_capsules,) # (n_capsules, capsule_dim,)\n",
    "decoder_input_shape = encoder_output_shape\n",
    "# decoder_input = Input(shape=decoder_input_shape)\n",
    "# decoder_input = encoder_model(encoder_input)\n",
    "decoder_input = encoder_output\n",
    "\n",
    "\n",
    "decoder_pipeline = list_decoders(decoder_input_shape, output_shape=input_shape)\n",
    "decoded = utils.composition(decoder_pipeline, decoder_input, verbose=False)\n",
    "\n",
    "# decoder_model = Model(decoder_input, decoded, name='decoder-')\n",
    "# decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_input = encoder_input\n",
    "ae_output = decoded\n",
    "# ae_output = decoder_model(encoder_model(encoder_input))\n",
    "# ae = Model(encoder_input, decoder_model(encoder_model(encoder_input)))\n",
    "# ae_output = decoded.\n",
    "# ae_encoder_output = encoder_model(encoder_input)\n",
    "# ae_decoder_output = decoder_model(ae_encoder_output)\n",
    "# ae_output = [ae_encoder_output, ae_decoder_output]\n",
    "\n",
    "ae = Model(ae_input, ae_output, name='AE')\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(alpha=1., beta=1.):\n",
    "#     encoder_loss = margin_loss(encoder_input, encoder_output)\n",
    "#     xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(ae_input), K.flatten(ae_output))\n",
    "#     # xent_loss = timesteps * notes * keras.metrics.binary_crossentropy(K.flatten(y1), K.flatten(y2))\n",
    "#     # return = K.mean(alpha * encoder_loss + beta * xent_loss)\n",
    "#     loss = K.mean(encoder_loss + xent_loss)\n",
    "#     return xent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_ = loss()\n",
    "# ae.add_loss(loss_)\n",
    "# ae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = [margin_loss, 'binary_crossentropy']\n",
    "loss = 'binary_crossentropy' # mse mae binary_crossentropy\n",
    "ae.compile(loss=loss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_ = lambda y_true, y_pred = loss(ae_input, ae_output)\n",
    "# loss_ = loss\n",
    "# loss_ = 'binary_crossentropy'\n",
    "\n",
    "# ae.compile(loss=loss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mod = 0.1\n",
    "whitening = False\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by dataset std\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_epsilon=10,\n",
    "        zca_whitening=whitening,\n",
    "        rotation_range=0,  # randomly rotate images in 0 to 180 degrees\n",
    "        width_shift_range=0.,  # note-channel mod, but not shuffled\n",
    "        height_shift_range=phase_mod,  # start_t, phase\n",
    "        horizontal_flip=False,  # reverse\n",
    "        vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_augmentation = False\n",
    "# data_augmentation = True\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "#     history = ae.fit(x_train, epochs=epochs, validation_data=(x_test, None))\n",
    "    history = ae.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')    \n",
    "    history = ae.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = datagen.random_transform(x_train[i])\n",
    "plot.multi(x[:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = datagen.standardize(x_train[i:i+batch_size])\n",
    "x.shape\n",
    "x = x[0]\n",
    "plot.multi(x[:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_train[i,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x = ae.predict(x_train[:10])\n",
    "plot.multi(x[i,:30,:,0])\n",
    "plot.multi(x_train[i,:30,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x[i,:,:,0]\n",
    "threshold = midi.MIDI_NOISE_FLOOR\n",
    "idx = x2[:,:] > threshold\n",
    "x2[idx] = 1\n",
    "plot.multi(x2[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
